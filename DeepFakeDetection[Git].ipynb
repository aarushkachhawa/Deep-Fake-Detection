{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepFakeDetection[Git].ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aarushkachhawa/Deep-Fake-Detection/blob/main/DeepFakeDetection%5BGit%5D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "%cd gdrive/MyDrive/DeepFakeDetection/Deep-Fake-Detection\n",
        "! git pull"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRkww81_Qa02",
        "outputId": "9dbe8b60-fa42-4aa2-f6c6-f2ca3eee70d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "/content/gdrive/MyDrive/DeepFakeDetection/Deep-Fake-Detection\n",
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E7brnzz-MJST",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3037b2ed-825d-45a7-a8e5-96c0b48cac07"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fc62bc49510>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "from skimage.io import imread\n",
        "from skimage.color import convert_colorspace\n",
        "from skimage import exposure\n",
        "from skimage import feature\n",
        "from skimage.color import rgb2gray\n",
        "from skimage.transform import resize\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import torch\n",
        "from numba import cuda \n",
        "import time\n",
        "\n",
        "from tensorflow import keras\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "import cv2\n",
        "import os\n",
        "import tqdm\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from tensorflow import keras\n",
        "from keras import Sequential\n",
        "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from keras import callbacks\n",
        "import keras\n",
        "from keras import losses\n",
        "import gc\n",
        "torch.manual_seed(111)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iZijEM0lN4BP"
      },
      "outputs": [],
      "source": [
        "\"\"\"def preProcess(image):\n",
        "    imgNewSpace = convert_colorspace(image, 'RGB', 'YCbCr')\n",
        "    gammaEnhanced = exposure.adjust_gamma(imgNewSpace, 2)\n",
        "    enhanced = convert_colorspace(gammaEnhanced, 'YCbCr','RGB')\n",
        "    grayimg = rgb2gray(enhanced)\n",
        "    edges = feature.canny(grayimg, sigma=3)\n",
        "    return grayimg\"\"\" \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "image = Image.open('real_sample/00005.jpg')\n",
        "image.size\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8AKAvYn3NCvo",
        "outputId": "e54c0c2a-c1ca-4162-c230-97aafc08eaa9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(256, 256)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "L0oLB5c3RNOn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir('real_sample/')"
      ],
      "metadata": {
        "id": "EhUk3_WxNpjJ",
        "outputId": "0609dd84-5b16-407c-c183-2663a53ce0f2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['00005.jpg',\n",
              " '00008.jpg',\n",
              " '00020.jpg',\n",
              " '00024.jpg',\n",
              " '00026.jpg',\n",
              " '00034.jpg',\n",
              " '00037.jpg',\n",
              " '00039.jpg',\n",
              " '00041.jpg',\n",
              " '00062.jpg',\n",
              " '00064.jpg',\n",
              " '00071.jpg',\n",
              " '00085.jpg',\n",
              " '00095.jpg',\n",
              " '00097.jpg',\n",
              " '00101.jpg',\n",
              " '00103.jpg',\n",
              " '00105.jpg',\n",
              " '00111.jpg',\n",
              " '00112.jpg',\n",
              " '00117.jpg',\n",
              " '00118.jpg',\n",
              " '00125.jpg',\n",
              " '00128.jpg',\n",
              " '00138.jpg',\n",
              " '00148.jpg',\n",
              " '00149.jpg',\n",
              " '00153.jpg',\n",
              " '00154.jpg',\n",
              " '00183.jpg',\n",
              " '00186.jpg',\n",
              " '00187.jpg',\n",
              " '00207.jpg',\n",
              " '00224.jpg',\n",
              " '00231.jpg',\n",
              " '00248.jpg',\n",
              " '00250.jpg',\n",
              " '00253.jpg',\n",
              " '00254.jpg',\n",
              " '00266.jpg',\n",
              " '00267.jpg',\n",
              " '00283.jpg',\n",
              " '00295.jpg',\n",
              " '00312.jpg',\n",
              " '00314.jpg',\n",
              " '00316.jpg',\n",
              " '00322.jpg',\n",
              " '00347.jpg',\n",
              " '00348.jpg',\n",
              " '00358.jpg',\n",
              " '00369.jpg',\n",
              " '00379.jpg',\n",
              " '00380.jpg',\n",
              " '00383.jpg',\n",
              " '00388.jpg',\n",
              " '00409.jpg',\n",
              " '00431.jpg',\n",
              " '00432.jpg',\n",
              " '00436.jpg',\n",
              " '00439.jpg',\n",
              " '00452.jpg',\n",
              " '00453.jpg',\n",
              " '00462.jpg',\n",
              " '.DS_Store',\n",
              " '00047 1.32.56 PM.jpg',\n",
              " '00463.jpg',\n",
              " '00464.jpg',\n",
              " '00466.jpg',\n",
              " '00468.jpg',\n",
              " '00471.jpg',\n",
              " '00480.jpg',\n",
              " '00492.jpg',\n",
              " '00494.jpg',\n",
              " '00496.jpg',\n",
              " '00501.jpg',\n",
              " '00502.jpg',\n",
              " '00512.jpg',\n",
              " '00523.jpg',\n",
              " '00540.jpg',\n",
              " '00541.jpg',\n",
              " '00543.jpg',\n",
              " '00547.jpg',\n",
              " '00551.jpg',\n",
              " '00554.jpg',\n",
              " '00565.jpg',\n",
              " '00566.jpg',\n",
              " '00573.jpg',\n",
              " '00586.jpg',\n",
              " '00600.jpg',\n",
              " '00605.jpg',\n",
              " '00608.jpg',\n",
              " '00609.jpg',\n",
              " '00618.jpg',\n",
              " '00620.jpg',\n",
              " '00626.jpg',\n",
              " '00630.jpg',\n",
              " '00638.jpg',\n",
              " '00639.jpg',\n",
              " '00647.jpg',\n",
              " '00649.jpg',\n",
              " '00661.jpg',\n",
              " '00664.jpg',\n",
              " '00671.jpg',\n",
              " '00673.jpg',\n",
              " '00679.jpg',\n",
              " '00681.jpg',\n",
              " '00684.jpg',\n",
              " '00686.jpg',\n",
              " '00694.jpg',\n",
              " '00703.jpg',\n",
              " '00734.jpg',\n",
              " '00740.jpg',\n",
              " '00764.jpg',\n",
              " '00774.jpg',\n",
              " '00796.jpg',\n",
              " '00803.jpg',\n",
              " '00804.jpg',\n",
              " '00812.jpg',\n",
              " '00824.jpg',\n",
              " '00830.jpg',\n",
              " '00835.jpg',\n",
              " '00841.jpg',\n",
              " '00848.jpg',\n",
              " '00862.jpg',\n",
              " '00865.jpg',\n",
              " '00868.jpg',\n",
              " '00898.jpg',\n",
              " '00900.jpg',\n",
              " '00910.jpg',\n",
              " '00911.jpg',\n",
              " '00912.jpg',\n",
              " '00918.jpg',\n",
              " '00940.jpg',\n",
              " '00946.jpg',\n",
              " '00947.jpg',\n",
              " '00948.jpg',\n",
              " '00949.jpg',\n",
              " '00967.jpg',\n",
              " '00970.jpg',\n",
              " '00982.jpg',\n",
              " '00991.jpg',\n",
              " '00992.jpg',\n",
              " '00994.jpg',\n",
              " '01004.jpg',\n",
              " '01005.jpg',\n",
              " '01015.jpg',\n",
              " '01017.jpg',\n",
              " '01019.jpg',\n",
              " '01020.jpg',\n",
              " '01026.jpg',\n",
              " '01029.jpg',\n",
              " '01035.jpg',\n",
              " '01063.jpg',\n",
              " '01068.jpg',\n",
              " '01079.jpg',\n",
              " '01082.jpg',\n",
              " '01089.jpg',\n",
              " '01122.jpg',\n",
              " '01142.jpg',\n",
              " '01146.jpg',\n",
              " '01148.jpg',\n",
              " '01161.jpg',\n",
              " '01166.jpg',\n",
              " '01172.jpg',\n",
              " '01177.jpg',\n",
              " '01183.jpg',\n",
              " '01203.jpg',\n",
              " '01212.jpg',\n",
              " '01214.jpg',\n",
              " '01220.jpg',\n",
              " '01222.jpg',\n",
              " '01226.jpg',\n",
              " '01237.jpg',\n",
              " '01244.jpg',\n",
              " '01245.jpg',\n",
              " '01256.jpg',\n",
              " '01261.jpg',\n",
              " '01269.jpg',\n",
              " '01280.jpg',\n",
              " '01282.jpg',\n",
              " '01291.jpg',\n",
              " '01293.jpg',\n",
              " '01299.jpg',\n",
              " '01320.jpg',\n",
              " '01332.jpg',\n",
              " '01333.jpg',\n",
              " '01335.jpg',\n",
              " '01336.jpg',\n",
              " '01346.jpg',\n",
              " '01347.jpg',\n",
              " '01356.jpg',\n",
              " '01357.jpg',\n",
              " '01360.jpg',\n",
              " '01361.jpg',\n",
              " '01365.jpg',\n",
              " '01367.jpg',\n",
              " '01385.jpg',\n",
              " '01388.jpg',\n",
              " '01392.jpg',\n",
              " '01403.jpg',\n",
              " '01406.jpg',\n",
              " '01409.jpg',\n",
              " '01413.jpg',\n",
              " '01445.jpg',\n",
              " '01460.jpg',\n",
              " '01470.jpg',\n",
              " '01475.jpg',\n",
              " '01491.jpg',\n",
              " '01514.jpg',\n",
              " '01517.jpg',\n",
              " '01518.jpg',\n",
              " '01526.jpg',\n",
              " '01527.jpg',\n",
              " '01537.jpg',\n",
              " '01551.jpg',\n",
              " '01555.jpg',\n",
              " '01560.jpg',\n",
              " '01563.jpg',\n",
              " '01575.jpg',\n",
              " '01578.jpg',\n",
              " '01590.jpg',\n",
              " '01593.jpg',\n",
              " '01597.jpg',\n",
              " '01598.jpg',\n",
              " '01601.jpg',\n",
              " '01603.jpg',\n",
              " '01608.jpg',\n",
              " '01610.jpg',\n",
              " '01626.jpg',\n",
              " '01631.jpg',\n",
              " '01638.jpg',\n",
              " '01654.jpg',\n",
              " '01665.jpg',\n",
              " '01668.jpg',\n",
              " '01671.jpg',\n",
              " '01676.jpg',\n",
              " '01681.jpg',\n",
              " '01695.jpg',\n",
              " '01699.jpg',\n",
              " '01704.jpg',\n",
              " '01705.jpg',\n",
              " '01707.jpg',\n",
              " '01708.jpg',\n",
              " '01709.jpg',\n",
              " '01714.jpg',\n",
              " '01720.jpg',\n",
              " '01742.jpg',\n",
              " '01752.jpg',\n",
              " '01755.jpg',\n",
              " '01757.jpg',\n",
              " '01758.jpg',\n",
              " '01767.jpg',\n",
              " '01774.jpg',\n",
              " '01782.jpg',\n",
              " '01793.jpg',\n",
              " '01806.jpg',\n",
              " '01807.jpg',\n",
              " '01808.jpg',\n",
              " '01814.jpg',\n",
              " '01815.jpg',\n",
              " '01823.jpg',\n",
              " '01830.jpg',\n",
              " '01832.jpg',\n",
              " '01845.jpg',\n",
              " '01846.jpg',\n",
              " '01857.jpg',\n",
              " '01866.jpg',\n",
              " '01872.jpg',\n",
              " '01877.jpg',\n",
              " '01884.jpg',\n",
              " '01887.jpg',\n",
              " '01890.jpg',\n",
              " '01894.jpg',\n",
              " '01910.jpg',\n",
              " '01911.jpg',\n",
              " '01912.jpg',\n",
              " '01918.jpg',\n",
              " '01919.jpg',\n",
              " '01924.jpg',\n",
              " '01932.jpg',\n",
              " '01933.jpg',\n",
              " '01951.jpg',\n",
              " '01956.jpg',\n",
              " '01960.jpg',\n",
              " '01962.jpg',\n",
              " '01972.jpg',\n",
              " '01978.jpg',\n",
              " '01979.jpg',\n",
              " '01990.jpg',\n",
              " '01991.jpg',\n",
              " '02002.jpg',\n",
              " '02010.jpg',\n",
              " '02018.jpg',\n",
              " '02042.jpg',\n",
              " '02044.jpg',\n",
              " '02046.jpg',\n",
              " '02052.jpg',\n",
              " '02060.jpg',\n",
              " '02061.jpg',\n",
              " '02073.jpg',\n",
              " '02081.jpg',\n",
              " '02084.jpg',\n",
              " '02086.jpg',\n",
              " '02116.jpg',\n",
              " '02123.jpg',\n",
              " '02126.jpg',\n",
              " '02131.jpg',\n",
              " '02136.jpg',\n",
              " '02139.jpg',\n",
              " '02142.jpg',\n",
              " '02143.jpg',\n",
              " '02147.jpg',\n",
              " '02164.jpg',\n",
              " '02165.jpg',\n",
              " '02168.jpg',\n",
              " '02175.jpg',\n",
              " '02179.jpg',\n",
              " '02192.jpg',\n",
              " '02198.jpg',\n",
              " '02199.jpg',\n",
              " '02204.jpg',\n",
              " '02223.jpg',\n",
              " '02252.jpg',\n",
              " '02253.jpg',\n",
              " '02266.jpg',\n",
              " '02269.jpg',\n",
              " '02277.jpg',\n",
              " '02278.jpg',\n",
              " '02280.jpg',\n",
              " '02281.jpg',\n",
              " '02284.jpg',\n",
              " '02293.jpg',\n",
              " '02309.jpg',\n",
              " '02318.jpg',\n",
              " '02326.jpg',\n",
              " '02343.jpg',\n",
              " '02363.jpg',\n",
              " '02372.jpg',\n",
              " '02380.jpg',\n",
              " '02386.jpg',\n",
              " '02394.jpg',\n",
              " '02399.jpg',\n",
              " '02400.jpg',\n",
              " '02407.jpg',\n",
              " '02430.jpg',\n",
              " '02431.jpg',\n",
              " '02433.jpg',\n",
              " '02434.jpg',\n",
              " '02439.jpg',\n",
              " '02445.jpg',\n",
              " '02448.jpg',\n",
              " '02453.jpg',\n",
              " '02457.jpg',\n",
              " '02461.jpg',\n",
              " '02463.jpg',\n",
              " '02465.jpg',\n",
              " '02467.jpg',\n",
              " '02474.jpg',\n",
              " '02480.jpg',\n",
              " '02483.jpg',\n",
              " '02487.jpg',\n",
              " '02488.jpg',\n",
              " '02505.jpg',\n",
              " '02512.jpg',\n",
              " '02518.jpg',\n",
              " '02534.jpg',\n",
              " '02544.jpg',\n",
              " '02545.jpg',\n",
              " '02555.jpg',\n",
              " '02560.jpg',\n",
              " '02561.jpg',\n",
              " '02564.jpg',\n",
              " '02571.jpg',\n",
              " '02574.jpg',\n",
              " '02588.jpg',\n",
              " '02607.jpg',\n",
              " '02622.jpg',\n",
              " '02623.jpg',\n",
              " '02627.jpg',\n",
              " '02634.jpg',\n",
              " '02635.jpg',\n",
              " '02644.jpg',\n",
              " '02661.jpg',\n",
              " '02672.jpg',\n",
              " '02713.jpg',\n",
              " '02717.jpg',\n",
              " '02734.jpg',\n",
              " '02736.jpg',\n",
              " '02738.jpg',\n",
              " '02740.jpg',\n",
              " '02742.jpg']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def loadImages(dataPath, category):\n",
        "  flat_data_arr=[] #input array\n",
        "  target_arr=[] #output array\n",
        "  for i in range(len(dataPath)):\n",
        "    for image in os.listdir(dataPath[i]):\n",
        "      if (not image.endswith('.jpg')):\n",
        "        continue\n",
        "      image_array = cv2.imread(os.path.join(dataPath[i], image))\n",
        "      if image_array is None:\n",
        "        print(image)\n",
        "      #print(image_array.shape)\n",
        "      image_resized = resize(image_array, (150,150,3))\n",
        "      #image_preprocess = preProcess(image_resized)\n",
        "      flat_data_arr.append(image_resized)\n",
        "      target_arr.append(category[i])\n",
        "  x = np.array(flat_data_arr)\n",
        "  y = np.array(target_arr)\n",
        "    #print(x)\n",
        "  return x, y\n"
      ],
      "metadata": {
        "id": "LQJ2uldVOYvO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dJt0_FURPCCO"
      },
      "outputs": [],
      "source": [
        "categories=[1,0] # [real, fake]\n",
        "\n",
        "#path which contains all the categories of images\n",
        "datadir='real_sample/'\n",
        "datadirs = ['real_sample/', 'fake_sample/'] \n",
        "\n",
        "x,y = loadImages(datadirs, categories)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kMP3QLEMPVv8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32c7a7cf-a973-4b12-e02c-1759ae623274"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(776, 150, 150, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "x.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v0FDFf2oOy0k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2180c380-f935-4998-ce26-e01a5c13daa4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[[0.04104575],\n",
              "         [0.04937847],\n",
              "         [0.04937847],\n",
              "         ...,\n",
              "         [0.10849359],\n",
              "         [0.11882196],\n",
              "         [0.13435137]],\n",
              "\n",
              "        [[0.09845194],\n",
              "         [0.11021664],\n",
              "         [0.12728854],\n",
              "         ...,\n",
              "         [0.12585063],\n",
              "         [0.14066388],\n",
              "         [0.14379085]],\n",
              "\n",
              "        [[0.14373542],\n",
              "         [0.14885804],\n",
              "         [0.15285804],\n",
              "         ...,\n",
              "         [0.70462013],\n",
              "         [0.7712868 ],\n",
              "         [0.80658092]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.12172549],\n",
              "         [0.13341176],\n",
              "         [0.13341176],\n",
              "         ...,\n",
              "         [0.41191843],\n",
              "         [0.49403765],\n",
              "         [0.69795765]],\n",
              "\n",
              "        [[0.43429595],\n",
              "         [0.51395608],\n",
              "         [0.72452131],\n",
              "         ...,\n",
              "         [0.41756706],\n",
              "         [0.49714876],\n",
              "         [0.71552784]],\n",
              "\n",
              "        [[0.38407529],\n",
              "         [0.47027137],\n",
              "         [0.67803608],\n",
              "         ...,\n",
              "         [0.71074667],\n",
              "         [0.76172706],\n",
              "         [0.7930719 ]]],\n",
              "\n",
              "\n",
              "       [[[0.12818301],\n",
              "         [0.13602614],\n",
              "         [0.13602614],\n",
              "         ...,\n",
              "         [0.40925333],\n",
              "         [0.49139556],\n",
              "         [0.69523869]],\n",
              "\n",
              "        [[0.42891503],\n",
              "         [0.51042423],\n",
              "         [0.71603329],\n",
              "         ...,\n",
              "         [0.42277124],\n",
              "         [0.50035887],\n",
              "         [0.71688889]],\n",
              "\n",
              "        [[0.38392157],\n",
              "         [0.46629908],\n",
              "         [0.67790693],\n",
              "         ...,\n",
              "         [0.71071895],\n",
              "         [0.76169935],\n",
              "         [0.7930719 ]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.12033987],\n",
              "         [0.13602614],\n",
              "         [0.1372549 ],\n",
              "         ...,\n",
              "         [0.28406484],\n",
              "         [0.33624941],\n",
              "         [0.55222013]],\n",
              "\n",
              "        [[0.3126583 ],\n",
              "         [0.36840401],\n",
              "         [0.58286153],\n",
              "         ...,\n",
              "         [0.28127163],\n",
              "         [0.34955207],\n",
              "         [0.57476898]],\n",
              "\n",
              "        [[0.26606379],\n",
              "         [0.33247059],\n",
              "         [0.56138562],\n",
              "         ...,\n",
              "         [0.71606257],\n",
              "         [0.76216993],\n",
              "         [0.79100654]]],\n",
              "\n",
              "\n",
              "       [[[0.11764706],\n",
              "         [0.13333333],\n",
              "         [0.1372549 ],\n",
              "         ...,\n",
              "         [0.30465098],\n",
              "         [0.35947608],\n",
              "         [0.5675498 ]],\n",
              "\n",
              "        [[0.31535111],\n",
              "         [0.37563869],\n",
              "         [0.58348183],\n",
              "         ...,\n",
              "         [0.31570458],\n",
              "         [0.39026824],\n",
              "         [0.61368993]],\n",
              "\n",
              "        [[0.27436863],\n",
              "         [0.34872157],\n",
              "         [0.57224941],\n",
              "         ...,\n",
              "         [0.71511111],\n",
              "         [0.76216993],\n",
              "         [0.79100654]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.20138562],\n",
              "         [0.44452288],\n",
              "         [0.99215686],\n",
              "         ...,\n",
              "         [0.38431373],\n",
              "         [0.43913725],\n",
              "         [0.64308654]],\n",
              "\n",
              "        [[0.38431373],\n",
              "         [0.44729412],\n",
              "         [0.64852288],\n",
              "         ...,\n",
              "         [0.10809813],\n",
              "         [0.09486937],\n",
              "         [0.0909478 ]],\n",
              "\n",
              "        [[0.04530876],\n",
              "         [0.03505882],\n",
              "         [0.03137255],\n",
              "         ...,\n",
              "         [0.2237837 ],\n",
              "         [0.48930004],\n",
              "         [0.99354248]]],\n",
              "\n",
              "\n",
              "       ...,\n",
              "\n",
              "\n",
              "       [[[1.        ],\n",
              "         [0.96078431],\n",
              "         [0.87194614],\n",
              "         ...,\n",
              "         [0.20007843],\n",
              "         [0.21960784],\n",
              "         [0.43921569]],\n",
              "\n",
              "        [[0.20279582],\n",
              "         [0.21576471],\n",
              "         [0.43921569],\n",
              "         ...,\n",
              "         [0.61291974],\n",
              "         [0.70439843],\n",
              "         [0.99213229]],\n",
              "\n",
              "        [[0.61945412],\n",
              "         [0.71357176],\n",
              "         [0.99215843],\n",
              "         ...,\n",
              "         [0.99215686],\n",
              "         [0.96862745],\n",
              "         [0.88881046]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.08627451],\n",
              "         [0.05882353],\n",
              "         [0.04705882],\n",
              "         ...,\n",
              "         [0.09819608],\n",
              "         [0.06663895],\n",
              "         [0.07058824]],\n",
              "\n",
              "        [[0.08750327],\n",
              "         [0.06064331],\n",
              "         [0.06492061],\n",
              "         ...,\n",
              "         [0.25509996],\n",
              "         [0.20827643],\n",
              "         [0.26338196]],\n",
              "\n",
              "        [[0.18824   ],\n",
              "         [0.14664523],\n",
              "         [0.20005542],\n",
              "         ...,\n",
              "         [0.28486989],\n",
              "         [0.26526205],\n",
              "         [0.30055617]]],\n",
              "\n",
              "\n",
              "       [[[0.64525978],\n",
              "         [0.71697935],\n",
              "         [0.78594667],\n",
              "         ...,\n",
              "         [0.29537412],\n",
              "         [0.32313882],\n",
              "         [0.35835451]],\n",
              "\n",
              "        [[0.35241708],\n",
              "         [0.37986806],\n",
              "         [0.41516218],\n",
              "         ...,\n",
              "         [0.18167198],\n",
              "         [0.22627329],\n",
              "         [0.29563277]],\n",
              "\n",
              "        [[0.34387399],\n",
              "         [0.38964863],\n",
              "         [0.43655059],\n",
              "         ...,\n",
              "         [0.3730766 ],\n",
              "         [0.49238257],\n",
              "         [0.62497203]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.51247216],\n",
              "         [0.57906039],\n",
              "         [0.6340915 ],\n",
              "         ...,\n",
              "         [0.30960157],\n",
              "         [0.40348235],\n",
              "         [0.58348235]],\n",
              "\n",
              "        [[0.32622484],\n",
              "         [0.44117908],\n",
              "         [0.63105987],\n",
              "         ...,\n",
              "         [0.19444706],\n",
              "         [0.30809412],\n",
              "         [0.5473098 ]],\n",
              "\n",
              "        [[0.18745725],\n",
              "         [0.29710588],\n",
              "         [0.53616157],\n",
              "         ...,\n",
              "         [0.50807216],\n",
              "         [0.69254275],\n",
              "         [0.93568   ]]],\n",
              "\n",
              "\n",
              "       [[[0.4670224 ],\n",
              "         [0.53368906],\n",
              "         [0.58466946],\n",
              "         ...,\n",
              "         [0.2292319 ],\n",
              "         [0.32834301],\n",
              "         [0.51919268]],\n",
              "\n",
              "        [[0.21235678],\n",
              "         [0.33269664],\n",
              "         [0.53023913],\n",
              "         ...,\n",
              "         [0.24488209],\n",
              "         [0.36622728],\n",
              "         [0.58144296]],\n",
              "\n",
              "        [[0.17456   ],\n",
              "         [0.29218248],\n",
              "         [0.51273464],\n",
              "         ...,\n",
              "         [0.49866196],\n",
              "         [0.68297569],\n",
              "         [0.92611294]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.83014379],\n",
              "         [0.94074231],\n",
              "         [0.99484967],\n",
              "         ...,\n",
              "         [0.21108026],\n",
              "         [0.31947399],\n",
              "         [0.65544627]],\n",
              "\n",
              "        [[0.21908497],\n",
              "         [0.33465952],\n",
              "         [0.66513847],\n",
              "         ...,\n",
              "         [0.24928105],\n",
              "         [0.40306597],\n",
              "         [0.70726083]],\n",
              "\n",
              "        [[0.25503425],\n",
              "         [0.41189699],\n",
              "         [0.70601464],\n",
              "         ...,\n",
              "         [0.5616746 ],\n",
              "         [0.69876706],\n",
              "         [0.78385481]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "x = np.resize(x, (x.shape[0], 150,150,1))\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WMigSHd2PbTJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ae8f633-11ea-4589-e25c-bf76047badaa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Splitted Successfully\n"
          ]
        }
      ],
      "source": [
        "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.20,random_state=77,stratify=y)\n",
        "print('Splitted Successfully')\n",
        "#x_train"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train"
      ],
      "metadata": {
        "id": "ZSjgSc7P3AIg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6142b7cb-12df-4bf3-956a-bda37194753a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[[0.64827329],\n",
              "         [0.5991681 ],\n",
              "         [0.62450858],\n",
              "         ...,\n",
              "         [0.01389281],\n",
              "         [0.00610039],\n",
              "         [0.05303007]],\n",
              "\n",
              "        [[0.06057429],\n",
              "         [0.05003834],\n",
              "         [0.10786841],\n",
              "         ...,\n",
              "         [0.02809342],\n",
              "         [0.01240715],\n",
              "         [0.0098712 ]],\n",
              "\n",
              "        [[0.0464868 ],\n",
              "         [0.03080052],\n",
              "         [0.02687895],\n",
              "         ...,\n",
              "         [0.8627451 ],\n",
              "         [0.83921569],\n",
              "         [0.79443852]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.44781699],\n",
              "         [0.40062902],\n",
              "         [0.30794771],\n",
              "         ...,\n",
              "         [0.2938102 ],\n",
              "         [0.2976549 ],\n",
              "         [0.39969569]],\n",
              "\n",
              "        [[0.29495895],\n",
              "         [0.29088523],\n",
              "         [0.40076288],\n",
              "         ...,\n",
              "         [0.4982651 ],\n",
              "         [0.47081412],\n",
              "         [0.52948078]],\n",
              "\n",
              "        [[0.49481569],\n",
              "         [0.46728784],\n",
              "         [0.52603137],\n",
              "         ...,\n",
              "         [0.73419451],\n",
              "         [0.51019294],\n",
              "         [0.14668967]]],\n",
              "\n",
              "\n",
              "       [[[0.31772549],\n",
              "         [0.46282353],\n",
              "         [0.45490196],\n",
              "         ...,\n",
              "         [0.34117804],\n",
              "         [0.41560941],\n",
              "         [0.7017302 ]],\n",
              "\n",
              "        [[0.3331519 ],\n",
              "         [0.41155869],\n",
              "         [0.68975477],\n",
              "         ...,\n",
              "         [0.32277281],\n",
              "         [0.39736105],\n",
              "         [0.65610614]],\n",
              "\n",
              "        [[0.3253349 ],\n",
              "         [0.40392   ],\n",
              "         [0.66266353],\n",
              "         ...,\n",
              "         [0.42729412],\n",
              "         [0.68481046],\n",
              "         [0.53322719]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.38684967],\n",
              "         [0.50057516],\n",
              "         [0.52156863],\n",
              "         ...,\n",
              "         [0.98839216],\n",
              "         [1.        ],\n",
              "         [1.        ]],\n",
              "\n",
              "        [[0.97231373],\n",
              "         [1.        ],\n",
              "         [0.99338562],\n",
              "         ...,\n",
              "         [0.27054153],\n",
              "         [0.37250231],\n",
              "         [0.55289447]],\n",
              "\n",
              "        [[0.22770928],\n",
              "         [0.32967007],\n",
              "         [0.51014065],\n",
              "         ...,\n",
              "         [0.19704349],\n",
              "         [0.32114806],\n",
              "         [0.23536314]]],\n",
              "\n",
              "\n",
              "       [[[0.4890719 ],\n",
              "         [0.49691503],\n",
              "         [0.5008366 ],\n",
              "         ...,\n",
              "         [0.60713882],\n",
              "         [0.57615529],\n",
              "         [0.77607686]],\n",
              "\n",
              "        [[0.59976471],\n",
              "         [0.57500654],\n",
              "         [0.78577778],\n",
              "         ...,\n",
              "         [0.72917176],\n",
              "         [0.71073882],\n",
              "         [0.90553464]],\n",
              "\n",
              "        [[0.75193412],\n",
              "         [0.73617255],\n",
              "         [0.92832471],\n",
              "         ...,\n",
              "         [0.13953255],\n",
              "         [0.19169098],\n",
              "         [0.27040837]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.64680453],\n",
              "         [0.66200122],\n",
              "         [0.7762163 ],\n",
              "         ...,\n",
              "         [0.21430065],\n",
              "         [0.09416837],\n",
              "         [0.20389386]],\n",
              "\n",
              "        [[0.21647617],\n",
              "         [0.09316619],\n",
              "         [0.20689168],\n",
              "         ...,\n",
              "         [0.63667974],\n",
              "         [0.6496732 ],\n",
              "         [0.75309804]],\n",
              "\n",
              "        [[0.63806536],\n",
              "         [0.65231529],\n",
              "         [0.75192   ],\n",
              "         ...,\n",
              "         [0.68292566],\n",
              "         [0.60980148],\n",
              "         [0.60080802]]],\n",
              "\n",
              "\n",
              "       ...,\n",
              "\n",
              "\n",
              "       [[[0.02745098],\n",
              "         [0.02745098],\n",
              "         [0.02352941],\n",
              "         ...,\n",
              "         [0.02737255],\n",
              "         [0.02352941],\n",
              "         [0.02745098]],\n",
              "\n",
              "        [[0.02745098],\n",
              "         [0.02745098],\n",
              "         [0.02745098],\n",
              "         ...,\n",
              "         [0.0568366 ],\n",
              "         [0.09553969],\n",
              "         [0.17397107]],\n",
              "\n",
              "        [[0.03898771],\n",
              "         [0.08212497],\n",
              "         [0.16055634],\n",
              "         ...,\n",
              "         [0.02745098],\n",
              "         [0.02745098],\n",
              "         [0.02745098]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.02352941],\n",
              "         [0.02352941],\n",
              "         [0.02352941],\n",
              "         ...,\n",
              "         [0.10941176],\n",
              "         [0.18753255],\n",
              "         [0.37160941]],\n",
              "\n",
              "        [[0.13331346],\n",
              "         [0.21689516],\n",
              "         [0.41320889],\n",
              "         ...,\n",
              "         [0.35720889],\n",
              "         [0.46455529],\n",
              "         [0.64764026]],\n",
              "\n",
              "        [[0.35018824],\n",
              "         [0.45230275],\n",
              "         [0.63277176],\n",
              "         ...,\n",
              "         [0.03748706],\n",
              "         [0.07908183],\n",
              "         [0.14982693]]],\n",
              "\n",
              "\n",
              "       [[[0.44077316],\n",
              "         [0.39328017],\n",
              "         [0.29959669],\n",
              "         ...,\n",
              "         [0.28506092],\n",
              "         [0.28370458],\n",
              "         [0.38566536]],\n",
              "\n",
              "        [[0.27773508],\n",
              "         [0.27189072],\n",
              "         [0.38192993],\n",
              "         ...,\n",
              "         [0.49833638],\n",
              "         [0.4708854 ],\n",
              "         [0.53278675]],\n",
              "\n",
              "        [[0.52454588],\n",
              "         [0.49440209],\n",
              "         [0.55861124],\n",
              "         ...,\n",
              "         [0.52294867],\n",
              "         [0.35201028],\n",
              "         [0.03216715]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.47653316],\n",
              "         [0.4216312 ],\n",
              "         [0.33143512],\n",
              "         ...,\n",
              "         [0.25202771],\n",
              "         [0.25218458],\n",
              "         [0.31508654]],\n",
              "\n",
              "        [[0.21105882],\n",
              "         [0.20752227],\n",
              "         [0.27026736],\n",
              "         ...,\n",
              "         [0.32503146],\n",
              "         [0.29796549],\n",
              "         [0.3865478 ]],\n",
              "\n",
              "        [[0.34123033],\n",
              "         [0.31103268],\n",
              "         [0.3975132 ],\n",
              "         ...,\n",
              "         [0.36667312],\n",
              "         [0.34302327],\n",
              "         [0.22029961]]],\n",
              "\n",
              "\n",
              "       [[[0.44054431],\n",
              "         [0.27484497],\n",
              "         [0.35675503],\n",
              "         ...,\n",
              "         [0.52549176],\n",
              "         [0.59239059],\n",
              "         [0.78431373]],\n",
              "\n",
              "        [[0.53298092],\n",
              "         [0.59429124],\n",
              "         [0.78508706],\n",
              "         ...,\n",
              "         [0.43361621],\n",
              "         [0.5054332 ],\n",
              "         [0.71202301]],\n",
              "\n",
              "        [[0.37278275],\n",
              "         [0.45497882],\n",
              "         [0.6587451 ],\n",
              "         ...,\n",
              "         [0.58023529],\n",
              "         [0.64444444],\n",
              "         [0.72141176]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.08766013],\n",
              "         [0.06805229],\n",
              "         [0.07197386],\n",
              "         ...,\n",
              "         [0.65652235],\n",
              "         [0.46695216],\n",
              "         [0.55319895]],\n",
              "\n",
              "        [[0.68299573],\n",
              "         [0.49622449],\n",
              "         [0.582499  ],\n",
              "         ...,\n",
              "         [0.50475085],\n",
              "         [0.32336523],\n",
              "         [0.39371817]],\n",
              "\n",
              "        [[0.36661281],\n",
              "         [0.18792471],\n",
              "         [0.26259137],\n",
              "         ...,\n",
              "         [0.0985478 ],\n",
              "         [0.06389542],\n",
              "         [0.06438501]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ON-0sG5-PcAP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ab1b3d9-a9e7-4249-8008-ee3f92694c2d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# device = cuda.get_current_device()\n",
        "# device\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_WjJPgb9PrlU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9befcfa5-f122-40f1-fe99-c1108a923d09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " batch_normalization_4 (Batc  (None, 150, 150, 1)      4         \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 150, 150, 6)       60        \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 75, 75, 6)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  (None, 75, 75, 6)        24        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 75, 75, 32)        1760      \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 37, 37, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " batch_normalization_6 (Batc  (None, 37, 37, 32)       128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 37, 37, 32)        0         \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 37, 37, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 18, 18, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " batch_normalization_7 (Batc  (None, 18, 18, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 18, 18, 64)        0         \n",
            "                                                                 \n",
            " global_average_pooling2d_1   (None, 64)               0         \n",
            " (GlobalAveragePooling2D)                                        \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 256)               16640     \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 128)               32896     \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 70,393\n",
            "Trainable params: 70,187\n",
            "Non-trainable params: 206\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
        "from keras.layers import Dropout, Flatten, Dense\n",
        "from keras.models import Sequential\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import (\n",
        "    BatchNormalization, SeparableConv2D, MaxPooling2D, Activation, Flatten, Dropout, Dense\n",
        ")\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "\n",
        "# Pamameters Initialization\n",
        "inputShape = (x_train.shape[1], x_train.shape[2],1)\n",
        "activation = 'relu' # change to relu\n",
        "padding = 'same'\n",
        "droprate = 0.1\n",
        "epsilon=0.001\n",
        "model = Sequential()\n",
        "model.add(keras.Input(shape=inputShape))\n",
        "model.add(BatchNormalization(input_shape=inputShape))\n",
        "model.add(Conv2D(filters=6, kernel_size=3, activation=activation, padding=padding))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(BatchNormalization(epsilon=epsilon))\n",
        "\n",
        "\n",
        "model.add(Conv2D(filters=32, kernel_size=3, activation=activation, padding=padding))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(BatchNormalization(epsilon=epsilon))\n",
        "model.add(Dropout(droprate))\n",
        "\n",
        "model.add(Conv2D(filters=64, kernel_size=3, activation=activation, padding=padding))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(BatchNormalization(epsilon=epsilon))\n",
        "model.add(Dropout(droprate))\n",
        "\n",
        "model.add(GlobalAveragePooling2D())\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, kernel_initializer='glorot_normal', activation='relu'))\n",
        "          \n",
        "model.add(Dense(128, kernel_initializer='glorot_normal', activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.summary() # Summary of the architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5cWWGVbWQNWq"
      },
      "outputs": [],
      "source": [
        "#from tensorflow.keras.optimizers import RMSprop\n",
        "#opt = rmsprop(lr=0.0001, decay=1e-6)\n",
        "#opt = Adam(lr=0.001, decay=1e-6)\n",
        "#model.compile(loss='Loss',optimizer=keras.optimizers.SGD(0.001), metrics=['accuracy'])\n",
        "#optimizer = tf.keras.optimizers.SGD(learning_rate=0.001, decay=1e-6)\n",
        "model.compile(optimizer = 'adam', loss = 'BinaryCrossentropy',\n",
        "             metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x_train, \n",
        "                    y_train, \n",
        "                    batch_size = 16, \n",
        "                    epochs = 1000, \n",
        "                    verbose = 1, \n",
        "                    validation_split = 0.2, \n",
        "                    shuffle = True)"
      ],
      "metadata": {
        "id": "R0XZPPcg1aPJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "175ff606-4c1f-405c-c1ae-dcc5282c37bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "31/31 [==============================] - 1s 18ms/step - loss: 0.7057 - accuracy: 0.5222 - val_loss: 0.6931 - val_accuracy: 0.5161\n",
            "Epoch 2/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.6972 - accuracy: 0.5464 - val_loss: 0.6946 - val_accuracy: 0.5161\n",
            "Epoch 3/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.6970 - accuracy: 0.5524 - val_loss: 0.6994 - val_accuracy: 0.5000\n",
            "Epoch 4/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.6955 - accuracy: 0.5282 - val_loss: 0.6982 - val_accuracy: 0.5161\n",
            "Epoch 5/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.6918 - accuracy: 0.5625 - val_loss: 0.7056 - val_accuracy: 0.5161\n",
            "Epoch 6/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.6926 - accuracy: 0.5625 - val_loss: 0.7187 - val_accuracy: 0.5161\n",
            "Epoch 7/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.6790 - accuracy: 0.5887 - val_loss: 0.7060 - val_accuracy: 0.5161\n",
            "Epoch 8/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.6880 - accuracy: 0.5423 - val_loss: 0.7021 - val_accuracy: 0.4839\n",
            "Epoch 9/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.6759 - accuracy: 0.5786 - val_loss: 0.7146 - val_accuracy: 0.4355\n",
            "Epoch 10/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.6844 - accuracy: 0.5625 - val_loss: 0.7105 - val_accuracy: 0.5081\n",
            "Epoch 11/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.6812 - accuracy: 0.5504 - val_loss: 0.7078 - val_accuracy: 0.5242\n",
            "Epoch 12/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.6785 - accuracy: 0.5706 - val_loss: 0.7008 - val_accuracy: 0.5161\n",
            "Epoch 13/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.6742 - accuracy: 0.5766 - val_loss: 0.7026 - val_accuracy: 0.5242\n",
            "Epoch 14/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.6652 - accuracy: 0.5806 - val_loss: 0.6946 - val_accuracy: 0.5323\n",
            "Epoch 15/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.6785 - accuracy: 0.5645 - val_loss: 0.6967 - val_accuracy: 0.4839\n",
            "Epoch 16/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.6549 - accuracy: 0.6230 - val_loss: 0.7188 - val_accuracy: 0.4839\n",
            "Epoch 17/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.6513 - accuracy: 0.5968 - val_loss: 0.6824 - val_accuracy: 0.5000\n",
            "Epoch 18/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.6468 - accuracy: 0.6149 - val_loss: 0.7143 - val_accuracy: 0.5242\n",
            "Epoch 19/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.6503 - accuracy: 0.6069 - val_loss: 0.6941 - val_accuracy: 0.5403\n",
            "Epoch 20/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.6433 - accuracy: 0.6109 - val_loss: 0.7097 - val_accuracy: 0.5403\n",
            "Epoch 21/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.6399 - accuracy: 0.6190 - val_loss: 0.7064 - val_accuracy: 0.5000\n",
            "Epoch 22/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.6404 - accuracy: 0.6371 - val_loss: 0.7174 - val_accuracy: 0.5323\n",
            "Epoch 23/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.6583 - accuracy: 0.6250 - val_loss: 0.6883 - val_accuracy: 0.5726\n",
            "Epoch 24/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.6242 - accuracy: 0.6613 - val_loss: 0.6834 - val_accuracy: 0.5565\n",
            "Epoch 25/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.6110 - accuracy: 0.6532 - val_loss: 0.6982 - val_accuracy: 0.5403\n",
            "Epoch 26/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.6309 - accuracy: 0.6371 - val_loss: 0.7183 - val_accuracy: 0.5081\n",
            "Epoch 27/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.6198 - accuracy: 0.6593 - val_loss: 0.6968 - val_accuracy: 0.5081\n",
            "Epoch 28/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.6129 - accuracy: 0.6512 - val_loss: 0.7297 - val_accuracy: 0.5645\n",
            "Epoch 29/1000\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.6065 - accuracy: 0.6573 - val_loss: 0.7488 - val_accuracy: 0.5565\n",
            "Epoch 30/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.6167 - accuracy: 0.6633 - val_loss: 0.7121 - val_accuracy: 0.5887\n",
            "Epoch 31/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.6095 - accuracy: 0.6694 - val_loss: 0.7586 - val_accuracy: 0.5403\n",
            "Epoch 32/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.5783 - accuracy: 0.6593 - val_loss: 0.7987 - val_accuracy: 0.5242\n",
            "Epoch 33/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.5921 - accuracy: 0.6774 - val_loss: 0.7259 - val_accuracy: 0.5323\n",
            "Epoch 34/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.5906 - accuracy: 0.6694 - val_loss: 0.7036 - val_accuracy: 0.5484\n",
            "Epoch 35/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.5869 - accuracy: 0.6915 - val_loss: 0.7712 - val_accuracy: 0.5565\n",
            "Epoch 36/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.5808 - accuracy: 0.6754 - val_loss: 0.7739 - val_accuracy: 0.5565\n",
            "Epoch 37/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.5648 - accuracy: 0.6976 - val_loss: 0.7925 - val_accuracy: 0.4839\n",
            "Epoch 38/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.5407 - accuracy: 0.7137 - val_loss: 0.8788 - val_accuracy: 0.5403\n",
            "Epoch 39/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.5589 - accuracy: 0.7238 - val_loss: 0.7751 - val_accuracy: 0.5565\n",
            "Epoch 40/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.5791 - accuracy: 0.6956 - val_loss: 0.7460 - val_accuracy: 0.5968\n",
            "Epoch 41/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.5953 - accuracy: 0.6855 - val_loss: 0.7157 - val_accuracy: 0.5968\n",
            "Epoch 42/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.5593 - accuracy: 0.7117 - val_loss: 0.7054 - val_accuracy: 0.5806\n",
            "Epoch 43/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.5562 - accuracy: 0.7056 - val_loss: 0.7489 - val_accuracy: 0.5726\n",
            "Epoch 44/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.5238 - accuracy: 0.7399 - val_loss: 0.7857 - val_accuracy: 0.5565\n",
            "Epoch 45/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.5049 - accuracy: 0.7419 - val_loss: 0.8283 - val_accuracy: 0.5242\n",
            "Epoch 46/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.5394 - accuracy: 0.7036 - val_loss: 0.7688 - val_accuracy: 0.5565\n",
            "Epoch 47/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.5129 - accuracy: 0.7540 - val_loss: 0.9168 - val_accuracy: 0.5484\n",
            "Epoch 48/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.5054 - accuracy: 0.7419 - val_loss: 0.7312 - val_accuracy: 0.6129\n",
            "Epoch 49/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.5006 - accuracy: 0.7661 - val_loss: 0.8161 - val_accuracy: 0.5484\n",
            "Epoch 50/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.4733 - accuracy: 0.7621 - val_loss: 0.7039 - val_accuracy: 0.6048\n",
            "Epoch 51/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.4975 - accuracy: 0.7702 - val_loss: 0.8363 - val_accuracy: 0.5081\n",
            "Epoch 52/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.5078 - accuracy: 0.7379 - val_loss: 0.8421 - val_accuracy: 0.5726\n",
            "Epoch 53/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.4772 - accuracy: 0.7500 - val_loss: 0.8415 - val_accuracy: 0.5645\n",
            "Epoch 54/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.4669 - accuracy: 0.7802 - val_loss: 0.9057 - val_accuracy: 0.5565\n",
            "Epoch 55/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.4444 - accuracy: 0.7984 - val_loss: 0.8354 - val_accuracy: 0.5403\n",
            "Epoch 56/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.4291 - accuracy: 0.7923 - val_loss: 1.0432 - val_accuracy: 0.5484\n",
            "Epoch 57/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.4700 - accuracy: 0.7802 - val_loss: 0.8699 - val_accuracy: 0.5645\n",
            "Epoch 58/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.4561 - accuracy: 0.7661 - val_loss: 1.1185 - val_accuracy: 0.4839\n",
            "Epoch 59/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.4302 - accuracy: 0.8004 - val_loss: 0.8376 - val_accuracy: 0.6210\n",
            "Epoch 60/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.3840 - accuracy: 0.8266 - val_loss: 0.8940 - val_accuracy: 0.5887\n",
            "Epoch 61/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.3969 - accuracy: 0.7964 - val_loss: 0.9920 - val_accuracy: 0.5806\n",
            "Epoch 62/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.4223 - accuracy: 0.7863 - val_loss: 0.8750 - val_accuracy: 0.5403\n",
            "Epoch 63/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.3903 - accuracy: 0.8165 - val_loss: 0.9862 - val_accuracy: 0.5806\n",
            "Epoch 64/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.3879 - accuracy: 0.8266 - val_loss: 1.1192 - val_accuracy: 0.5484\n",
            "Epoch 65/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.4065 - accuracy: 0.8206 - val_loss: 0.8106 - val_accuracy: 0.6210\n",
            "Epoch 66/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.3692 - accuracy: 0.8387 - val_loss: 0.8196 - val_accuracy: 0.6290\n",
            "Epoch 67/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.3715 - accuracy: 0.8347 - val_loss: 0.9642 - val_accuracy: 0.6048\n",
            "Epoch 68/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.3642 - accuracy: 0.8347 - val_loss: 0.8806 - val_accuracy: 0.5323\n",
            "Epoch 69/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.3615 - accuracy: 0.8347 - val_loss: 0.9025 - val_accuracy: 0.6129\n",
            "Epoch 70/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.3348 - accuracy: 0.8488 - val_loss: 0.9613 - val_accuracy: 0.5887\n",
            "Epoch 71/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.3403 - accuracy: 0.8468 - val_loss: 0.9422 - val_accuracy: 0.6048\n",
            "Epoch 72/1000\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.3242 - accuracy: 0.8508 - val_loss: 0.9969 - val_accuracy: 0.5726\n",
            "Epoch 73/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.3161 - accuracy: 0.8649 - val_loss: 0.9278 - val_accuracy: 0.5887\n",
            "Epoch 74/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.2971 - accuracy: 0.8629 - val_loss: 1.1281 - val_accuracy: 0.6048\n",
            "Epoch 75/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.3289 - accuracy: 0.8690 - val_loss: 1.6609 - val_accuracy: 0.5161\n",
            "Epoch 76/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.3392 - accuracy: 0.8730 - val_loss: 0.9113 - val_accuracy: 0.5403\n",
            "Epoch 77/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.2889 - accuracy: 0.8831 - val_loss: 0.9641 - val_accuracy: 0.5887\n",
            "Epoch 78/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.2458 - accuracy: 0.8810 - val_loss: 0.9760 - val_accuracy: 0.6129\n",
            "Epoch 79/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.3413 - accuracy: 0.8468 - val_loss: 1.1458 - val_accuracy: 0.5968\n",
            "Epoch 80/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.2752 - accuracy: 0.8952 - val_loss: 1.0394 - val_accuracy: 0.6129\n",
            "Epoch 81/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.2686 - accuracy: 0.8810 - val_loss: 1.0970 - val_accuracy: 0.5887\n",
            "Epoch 82/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.2260 - accuracy: 0.9133 - val_loss: 1.1005 - val_accuracy: 0.5806\n",
            "Epoch 83/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.2825 - accuracy: 0.8730 - val_loss: 1.1579 - val_accuracy: 0.5645\n",
            "Epoch 84/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.2916 - accuracy: 0.8690 - val_loss: 1.0174 - val_accuracy: 0.6048\n",
            "Epoch 85/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.2715 - accuracy: 0.8770 - val_loss: 1.1095 - val_accuracy: 0.5806\n",
            "Epoch 86/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.2295 - accuracy: 0.9052 - val_loss: 1.0103 - val_accuracy: 0.6129\n",
            "Epoch 87/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.2562 - accuracy: 0.9093 - val_loss: 1.0543 - val_accuracy: 0.5968\n",
            "Epoch 88/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.2555 - accuracy: 0.8911 - val_loss: 1.1810 - val_accuracy: 0.6452\n",
            "Epoch 89/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.2084 - accuracy: 0.9073 - val_loss: 1.0216 - val_accuracy: 0.6774\n",
            "Epoch 90/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.1817 - accuracy: 0.9274 - val_loss: 1.0437 - val_accuracy: 0.6532\n",
            "Epoch 91/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.2079 - accuracy: 0.9194 - val_loss: 1.5075 - val_accuracy: 0.6048\n",
            "Epoch 92/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.2767 - accuracy: 0.8790 - val_loss: 1.2097 - val_accuracy: 0.5968\n",
            "Epoch 93/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.2074 - accuracy: 0.9234 - val_loss: 1.4018 - val_accuracy: 0.5806\n",
            "Epoch 94/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.2045 - accuracy: 0.9274 - val_loss: 1.2652 - val_accuracy: 0.5484\n",
            "Epoch 95/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.1735 - accuracy: 0.9194 - val_loss: 1.2202 - val_accuracy: 0.6048\n",
            "Epoch 96/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.1581 - accuracy: 0.9355 - val_loss: 1.1627 - val_accuracy: 0.6048\n",
            "Epoch 97/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.1949 - accuracy: 0.9294 - val_loss: 1.3096 - val_accuracy: 0.6210\n",
            "Epoch 98/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.1792 - accuracy: 0.9335 - val_loss: 1.4003 - val_accuracy: 0.5887\n",
            "Epoch 99/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.1965 - accuracy: 0.9214 - val_loss: 1.2657 - val_accuracy: 0.6129\n",
            "Epoch 100/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.1912 - accuracy: 0.9153 - val_loss: 1.1640 - val_accuracy: 0.6129\n",
            "Epoch 101/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.1588 - accuracy: 0.9294 - val_loss: 1.3544 - val_accuracy: 0.5806\n",
            "Epoch 102/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.1384 - accuracy: 0.9516 - val_loss: 1.2267 - val_accuracy: 0.6371\n",
            "Epoch 103/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.1347 - accuracy: 0.9516 - val_loss: 1.3520 - val_accuracy: 0.6048\n",
            "Epoch 104/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.1367 - accuracy: 0.9516 - val_loss: 1.4570 - val_accuracy: 0.6774\n",
            "Epoch 105/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.1508 - accuracy: 0.9335 - val_loss: 1.3261 - val_accuracy: 0.6694\n",
            "Epoch 106/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.2042 - accuracy: 0.9254 - val_loss: 1.4712 - val_accuracy: 0.6290\n",
            "Epoch 107/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.2039 - accuracy: 0.9194 - val_loss: 1.3651 - val_accuracy: 0.5887\n",
            "Epoch 108/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.1700 - accuracy: 0.9274 - val_loss: 1.4001 - val_accuracy: 0.6048\n",
            "Epoch 109/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.1135 - accuracy: 0.9617 - val_loss: 1.2222 - val_accuracy: 0.6210\n",
            "Epoch 110/1000\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.1517 - accuracy: 0.9355 - val_loss: 1.8201 - val_accuracy: 0.5968\n",
            "Epoch 111/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.1450 - accuracy: 0.9456 - val_loss: 1.3306 - val_accuracy: 0.6048\n",
            "Epoch 112/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.1249 - accuracy: 0.9456 - val_loss: 1.2903 - val_accuracy: 0.6210\n",
            "Epoch 113/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.1749 - accuracy: 0.9415 - val_loss: 1.3642 - val_accuracy: 0.6452\n",
            "Epoch 114/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.1555 - accuracy: 0.9395 - val_loss: 1.3076 - val_accuracy: 0.6694\n",
            "Epoch 115/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.1160 - accuracy: 0.9637 - val_loss: 1.3907 - val_accuracy: 0.5968\n",
            "Epoch 116/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.1538 - accuracy: 0.9496 - val_loss: 1.1609 - val_accuracy: 0.6613\n",
            "Epoch 117/1000\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.1115 - accuracy: 0.9536 - val_loss: 1.3324 - val_accuracy: 0.6452\n",
            "Epoch 118/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.1033 - accuracy: 0.9577 - val_loss: 1.2603 - val_accuracy: 0.6371\n",
            "Epoch 119/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.1438 - accuracy: 0.9456 - val_loss: 1.3904 - val_accuracy: 0.6532\n",
            "Epoch 120/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.1768 - accuracy: 0.9395 - val_loss: 1.3727 - val_accuracy: 0.5968\n",
            "Epoch 121/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.1477 - accuracy: 0.9456 - val_loss: 1.3584 - val_accuracy: 0.6210\n",
            "Epoch 122/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.1194 - accuracy: 0.9577 - val_loss: 1.6098 - val_accuracy: 0.6210\n",
            "Epoch 123/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0865 - accuracy: 0.9657 - val_loss: 1.4849 - val_accuracy: 0.6371\n",
            "Epoch 124/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0844 - accuracy: 0.9698 - val_loss: 1.6495 - val_accuracy: 0.5806\n",
            "Epoch 125/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0968 - accuracy: 0.9718 - val_loss: 1.4744 - val_accuracy: 0.6532\n",
            "Epoch 126/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0935 - accuracy: 0.9577 - val_loss: 1.3860 - val_accuracy: 0.6613\n",
            "Epoch 127/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.1013 - accuracy: 0.9637 - val_loss: 1.4061 - val_accuracy: 0.6210\n",
            "Epoch 128/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0952 - accuracy: 0.9718 - val_loss: 1.3769 - val_accuracy: 0.6613\n",
            "Epoch 129/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0568 - accuracy: 0.9798 - val_loss: 1.5847 - val_accuracy: 0.6371\n",
            "Epoch 130/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0630 - accuracy: 0.9798 - val_loss: 1.4880 - val_accuracy: 0.6452\n",
            "Epoch 131/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0697 - accuracy: 0.9758 - val_loss: 1.4790 - val_accuracy: 0.6774\n",
            "Epoch 132/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0697 - accuracy: 0.9758 - val_loss: 1.7085 - val_accuracy: 0.6452\n",
            "Epoch 133/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0788 - accuracy: 0.9758 - val_loss: 1.7165 - val_accuracy: 0.5968\n",
            "Epoch 134/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.1002 - accuracy: 0.9677 - val_loss: 1.6011 - val_accuracy: 0.5968\n",
            "Epoch 135/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.1399 - accuracy: 0.9516 - val_loss: 1.6583 - val_accuracy: 0.6532\n",
            "Epoch 136/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.1365 - accuracy: 0.9516 - val_loss: 1.2524 - val_accuracy: 0.6452\n",
            "Epoch 137/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.1140 - accuracy: 0.9536 - val_loss: 1.5753 - val_accuracy: 0.6210\n",
            "Epoch 138/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0926 - accuracy: 0.9617 - val_loss: 1.4899 - val_accuracy: 0.5887\n",
            "Epoch 139/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.1029 - accuracy: 0.9577 - val_loss: 1.9393 - val_accuracy: 0.5968\n",
            "Epoch 140/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0859 - accuracy: 0.9738 - val_loss: 1.3513 - val_accuracy: 0.6613\n",
            "Epoch 141/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0734 - accuracy: 0.9778 - val_loss: 1.4160 - val_accuracy: 0.6613\n",
            "Epoch 142/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0524 - accuracy: 0.9839 - val_loss: 1.4811 - val_accuracy: 0.6935\n",
            "Epoch 143/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0530 - accuracy: 0.9839 - val_loss: 1.4204 - val_accuracy: 0.6290\n",
            "Epoch 144/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0730 - accuracy: 0.9718 - val_loss: 1.9345 - val_accuracy: 0.6290\n",
            "Epoch 145/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0577 - accuracy: 0.9738 - val_loss: 1.6568 - val_accuracy: 0.6532\n",
            "Epoch 146/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.1220 - accuracy: 0.9597 - val_loss: 1.8590 - val_accuracy: 0.5645\n",
            "Epoch 147/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0977 - accuracy: 0.9617 - val_loss: 1.6215 - val_accuracy: 0.6694\n",
            "Epoch 148/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0646 - accuracy: 0.9778 - val_loss: 2.0132 - val_accuracy: 0.6210\n",
            "Epoch 149/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0851 - accuracy: 0.9819 - val_loss: 1.5246 - val_accuracy: 0.6532\n",
            "Epoch 150/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0483 - accuracy: 0.9839 - val_loss: 1.6792 - val_accuracy: 0.6452\n",
            "Epoch 151/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0590 - accuracy: 0.9839 - val_loss: 1.7268 - val_accuracy: 0.6371\n",
            "Epoch 152/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0350 - accuracy: 0.9899 - val_loss: 1.8080 - val_accuracy: 0.6210\n",
            "Epoch 153/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0870 - accuracy: 0.9677 - val_loss: 1.9342 - val_accuracy: 0.5968\n",
            "Epoch 154/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0820 - accuracy: 0.9738 - val_loss: 2.0327 - val_accuracy: 0.5806\n",
            "Epoch 155/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0727 - accuracy: 0.9839 - val_loss: 1.9716 - val_accuracy: 0.6452\n",
            "Epoch 156/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0632 - accuracy: 0.9819 - val_loss: 1.7444 - val_accuracy: 0.6290\n",
            "Epoch 157/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0441 - accuracy: 0.9879 - val_loss: 1.7795 - val_accuracy: 0.6129\n",
            "Epoch 158/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0435 - accuracy: 0.9859 - val_loss: 1.7595 - val_accuracy: 0.6371\n",
            "Epoch 159/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0742 - accuracy: 0.9738 - val_loss: 2.8765 - val_accuracy: 0.5806\n",
            "Epoch 160/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.1363 - accuracy: 0.9617 - val_loss: 1.9527 - val_accuracy: 0.5726\n",
            "Epoch 161/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0911 - accuracy: 0.9738 - val_loss: 1.6212 - val_accuracy: 0.6371\n",
            "Epoch 162/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0522 - accuracy: 0.9839 - val_loss: 1.7358 - val_accuracy: 0.6210\n",
            "Epoch 163/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0524 - accuracy: 0.9819 - val_loss: 1.7568 - val_accuracy: 0.6532\n",
            "Epoch 164/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0480 - accuracy: 0.9879 - val_loss: 1.7328 - val_accuracy: 0.6129\n",
            "Epoch 165/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0232 - accuracy: 1.0000 - val_loss: 1.6105 - val_accuracy: 0.6855\n",
            "Epoch 166/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0543 - accuracy: 0.9798 - val_loss: 1.9426 - val_accuracy: 0.6532\n",
            "Epoch 167/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0497 - accuracy: 0.9819 - val_loss: 1.9808 - val_accuracy: 0.6129\n",
            "Epoch 168/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0372 - accuracy: 0.9859 - val_loss: 1.9278 - val_accuracy: 0.6613\n",
            "Epoch 169/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0187 - accuracy: 0.9960 - val_loss: 1.8245 - val_accuracy: 0.6613\n",
            "Epoch 170/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0196 - accuracy: 0.9940 - val_loss: 1.9473 - val_accuracy: 0.6210\n",
            "Epoch 171/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0428 - accuracy: 0.9859 - val_loss: 1.6729 - val_accuracy: 0.6452\n",
            "Epoch 172/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0354 - accuracy: 0.9819 - val_loss: 2.1819 - val_accuracy: 0.6290\n",
            "Epoch 173/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0643 - accuracy: 0.9718 - val_loss: 2.2232 - val_accuracy: 0.5887\n",
            "Epoch 174/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0768 - accuracy: 0.9698 - val_loss: 3.2271 - val_accuracy: 0.5484\n",
            "Epoch 175/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.1352 - accuracy: 0.9577 - val_loss: 2.1072 - val_accuracy: 0.5806\n",
            "Epoch 176/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.1258 - accuracy: 0.9577 - val_loss: 1.7382 - val_accuracy: 0.5726\n",
            "Epoch 177/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0788 - accuracy: 0.9698 - val_loss: 1.9185 - val_accuracy: 0.5887\n",
            "Epoch 178/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0641 - accuracy: 0.9738 - val_loss: 1.6195 - val_accuracy: 0.6129\n",
            "Epoch 179/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0322 - accuracy: 0.9859 - val_loss: 1.8477 - val_accuracy: 0.6532\n",
            "Epoch 180/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0355 - accuracy: 0.9859 - val_loss: 1.8129 - val_accuracy: 0.6532\n",
            "Epoch 181/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0952 - accuracy: 0.9677 - val_loss: 1.7654 - val_accuracy: 0.6210\n",
            "Epoch 182/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0457 - accuracy: 0.9839 - val_loss: 1.6381 - val_accuracy: 0.6613\n",
            "Epoch 183/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0271 - accuracy: 0.9919 - val_loss: 2.5245 - val_accuracy: 0.5806\n",
            "Epoch 184/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0299 - accuracy: 0.9899 - val_loss: 1.5787 - val_accuracy: 0.6613\n",
            "Epoch 185/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0331 - accuracy: 0.9879 - val_loss: 1.8560 - val_accuracy: 0.6452\n",
            "Epoch 186/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0650 - accuracy: 0.9798 - val_loss: 1.7495 - val_accuracy: 0.6371\n",
            "Epoch 187/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0339 - accuracy: 0.9859 - val_loss: 1.8228 - val_accuracy: 0.6452\n",
            "Epoch 188/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0205 - accuracy: 0.9940 - val_loss: 2.1340 - val_accuracy: 0.6210\n",
            "Epoch 189/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0259 - accuracy: 0.9899 - val_loss: 2.0265 - val_accuracy: 0.6613\n",
            "Epoch 190/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0688 - accuracy: 0.9758 - val_loss: 1.7363 - val_accuracy: 0.6532\n",
            "Epoch 191/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0595 - accuracy: 0.9798 - val_loss: 1.9904 - val_accuracy: 0.6452\n",
            "Epoch 192/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0737 - accuracy: 0.9738 - val_loss: 1.7470 - val_accuracy: 0.6613\n",
            "Epoch 193/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0412 - accuracy: 0.9819 - val_loss: 2.0482 - val_accuracy: 0.6129\n",
            "Epoch 194/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0547 - accuracy: 0.9778 - val_loss: 1.7983 - val_accuracy: 0.6129\n",
            "Epoch 195/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0344 - accuracy: 0.9919 - val_loss: 2.2856 - val_accuracy: 0.6129\n",
            "Epoch 196/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0653 - accuracy: 0.9738 - val_loss: 2.3017 - val_accuracy: 0.6048\n",
            "Epoch 197/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0581 - accuracy: 0.9798 - val_loss: 2.1211 - val_accuracy: 0.5887\n",
            "Epoch 198/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0771 - accuracy: 0.9798 - val_loss: 2.0598 - val_accuracy: 0.6210\n",
            "Epoch 199/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0882 - accuracy: 0.9758 - val_loss: 1.5108 - val_accuracy: 0.6532\n",
            "Epoch 200/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0445 - accuracy: 0.9819 - val_loss: 1.7328 - val_accuracy: 0.6613\n",
            "Epoch 201/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0280 - accuracy: 0.9940 - val_loss: 1.8076 - val_accuracy: 0.6371\n",
            "Epoch 202/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0334 - accuracy: 0.9879 - val_loss: 1.9451 - val_accuracy: 0.6532\n",
            "Epoch 203/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0288 - accuracy: 0.9899 - val_loss: 1.8658 - val_accuracy: 0.6694\n",
            "Epoch 204/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0333 - accuracy: 0.9899 - val_loss: 1.9390 - val_accuracy: 0.6371\n",
            "Epoch 205/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0318 - accuracy: 0.9899 - val_loss: 2.0299 - val_accuracy: 0.6290\n",
            "Epoch 206/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0224 - accuracy: 0.9940 - val_loss: 2.4928 - val_accuracy: 0.5968\n",
            "Epoch 207/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0210 - accuracy: 0.9940 - val_loss: 2.1850 - val_accuracy: 0.6210\n",
            "Epoch 208/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0233 - accuracy: 0.9919 - val_loss: 2.3014 - val_accuracy: 0.6532\n",
            "Epoch 209/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0463 - accuracy: 0.9819 - val_loss: 2.0489 - val_accuracy: 0.6210\n",
            "Epoch 210/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0462 - accuracy: 0.9798 - val_loss: 2.0524 - val_accuracy: 0.6210\n",
            "Epoch 211/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0328 - accuracy: 0.9899 - val_loss: 2.0967 - val_accuracy: 0.6935\n",
            "Epoch 212/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0700 - accuracy: 0.9718 - val_loss: 2.2685 - val_accuracy: 0.5726\n",
            "Epoch 213/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.1029 - accuracy: 0.9617 - val_loss: 2.3778 - val_accuracy: 0.5887\n",
            "Epoch 214/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0702 - accuracy: 0.9718 - val_loss: 2.1989 - val_accuracy: 0.5968\n",
            "Epoch 215/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0619 - accuracy: 0.9859 - val_loss: 1.9231 - val_accuracy: 0.6371\n",
            "Epoch 216/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0474 - accuracy: 0.9839 - val_loss: 2.4612 - val_accuracy: 0.6129\n",
            "Epoch 217/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0501 - accuracy: 0.9798 - val_loss: 2.0836 - val_accuracy: 0.6048\n",
            "Epoch 218/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0138 - accuracy: 0.9980 - val_loss: 2.1930 - val_accuracy: 0.5806\n",
            "Epoch 219/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0177 - accuracy: 0.9940 - val_loss: 2.3736 - val_accuracy: 0.6290\n",
            "Epoch 220/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0217 - accuracy: 0.9899 - val_loss: 2.6014 - val_accuracy: 0.6129\n",
            "Epoch 221/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0267 - accuracy: 0.9919 - val_loss: 2.3710 - val_accuracy: 0.6371\n",
            "Epoch 222/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0307 - accuracy: 0.9839 - val_loss: 1.8483 - val_accuracy: 0.6613\n",
            "Epoch 223/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0193 - accuracy: 0.9940 - val_loss: 1.9731 - val_accuracy: 0.6371\n",
            "Epoch 224/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0135 - accuracy: 0.9960 - val_loss: 2.2025 - val_accuracy: 0.6129\n",
            "Epoch 225/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0159 - accuracy: 0.9960 - val_loss: 2.3405 - val_accuracy: 0.6371\n",
            "Epoch 226/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0070 - accuracy: 0.9980 - val_loss: 2.1711 - val_accuracy: 0.6452\n",
            "Epoch 227/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 2.2152 - val_accuracy: 0.6452\n",
            "Epoch 228/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 2.3541 - val_accuracy: 0.6613\n",
            "Epoch 229/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 2.1505 - val_accuracy: 0.6774\n",
            "Epoch 230/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0069 - accuracy: 0.9980 - val_loss: 2.2450 - val_accuracy: 0.6210\n",
            "Epoch 231/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0457 - accuracy: 0.9879 - val_loss: 2.4474 - val_accuracy: 0.6452\n",
            "Epoch 232/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0446 - accuracy: 0.9879 - val_loss: 2.9056 - val_accuracy: 0.6290\n",
            "Epoch 233/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.1508 - accuracy: 0.9536 - val_loss: 1.6955 - val_accuracy: 0.6694\n",
            "Epoch 234/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.1810 - accuracy: 0.9415 - val_loss: 1.9034 - val_accuracy: 0.5726\n",
            "Epoch 235/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0497 - accuracy: 0.9819 - val_loss: 2.4385 - val_accuracy: 0.5887\n",
            "Epoch 236/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0740 - accuracy: 0.9798 - val_loss: 1.7169 - val_accuracy: 0.6290\n",
            "Epoch 237/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0893 - accuracy: 0.9738 - val_loss: 2.3715 - val_accuracy: 0.5645\n",
            "Epoch 238/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0866 - accuracy: 0.9617 - val_loss: 2.2337 - val_accuracy: 0.5968\n",
            "Epoch 239/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0964 - accuracy: 0.9617 - val_loss: 2.1039 - val_accuracy: 0.6048\n",
            "Epoch 240/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0732 - accuracy: 0.9778 - val_loss: 1.9971 - val_accuracy: 0.5887\n",
            "Epoch 241/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0406 - accuracy: 0.9839 - val_loss: 1.9366 - val_accuracy: 0.5887\n",
            "Epoch 242/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0206 - accuracy: 0.9940 - val_loss: 1.9623 - val_accuracy: 0.6129\n",
            "Epoch 243/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0280 - accuracy: 0.9919 - val_loss: 1.6665 - val_accuracy: 0.6210\n",
            "Epoch 244/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0261 - accuracy: 0.9879 - val_loss: 1.8106 - val_accuracy: 0.6371\n",
            "Epoch 245/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0139 - accuracy: 0.9960 - val_loss: 1.9158 - val_accuracy: 0.6210\n",
            "Epoch 246/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0298 - accuracy: 0.9919 - val_loss: 2.0193 - val_accuracy: 0.6129\n",
            "Epoch 247/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0644 - accuracy: 0.9798 - val_loss: 1.9915 - val_accuracy: 0.6210\n",
            "Epoch 248/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0834 - accuracy: 0.9798 - val_loss: 2.0377 - val_accuracy: 0.5968\n",
            "Epoch 249/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0490 - accuracy: 0.9819 - val_loss: 2.0520 - val_accuracy: 0.5726\n",
            "Epoch 250/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0298 - accuracy: 0.9899 - val_loss: 1.9349 - val_accuracy: 0.5806\n",
            "Epoch 251/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0217 - accuracy: 0.9940 - val_loss: 2.0696 - val_accuracy: 0.6532\n",
            "Epoch 252/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0528 - accuracy: 0.9819 - val_loss: 1.9481 - val_accuracy: 0.6129\n",
            "Epoch 253/1000\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.0273 - accuracy: 0.9919 - val_loss: 1.9031 - val_accuracy: 0.6210\n",
            "Epoch 254/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0262 - accuracy: 0.9919 - val_loss: 2.0365 - val_accuracy: 0.5565\n",
            "Epoch 255/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0113 - accuracy: 0.9960 - val_loss: 1.9861 - val_accuracy: 0.6048\n",
            "Epoch 256/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0094 - accuracy: 0.9980 - val_loss: 2.0491 - val_accuracy: 0.6371\n",
            "Epoch 257/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 2.0682 - val_accuracy: 0.6371\n",
            "Epoch 258/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0063 - accuracy: 0.9980 - val_loss: 2.0932 - val_accuracy: 0.6613\n",
            "Epoch 259/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0168 - accuracy: 0.9919 - val_loss: 2.3464 - val_accuracy: 0.6371\n",
            "Epoch 260/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0080 - accuracy: 0.9980 - val_loss: 2.5607 - val_accuracy: 0.6210\n",
            "Epoch 261/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0125 - accuracy: 0.9960 - val_loss: 2.3273 - val_accuracy: 0.6371\n",
            "Epoch 262/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0099 - accuracy: 0.9960 - val_loss: 2.2177 - val_accuracy: 0.6613\n",
            "Epoch 263/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0080 - accuracy: 0.9960 - val_loss: 2.2773 - val_accuracy: 0.6613\n",
            "Epoch 264/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0161 - accuracy: 0.9960 - val_loss: 2.5277 - val_accuracy: 0.6371\n",
            "Epoch 265/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.1265 - accuracy: 0.9617 - val_loss: 2.1806 - val_accuracy: 0.6129\n",
            "Epoch 266/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.1499 - accuracy: 0.9476 - val_loss: 2.1651 - val_accuracy: 0.5726\n",
            "Epoch 267/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.1094 - accuracy: 0.9577 - val_loss: 1.9806 - val_accuracy: 0.6048\n",
            "Epoch 268/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0679 - accuracy: 0.9778 - val_loss: 1.9002 - val_accuracy: 0.6452\n",
            "Epoch 269/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0305 - accuracy: 0.9859 - val_loss: 2.2328 - val_accuracy: 0.6371\n",
            "Epoch 270/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0206 - accuracy: 0.9960 - val_loss: 2.1174 - val_accuracy: 0.6532\n",
            "Epoch 271/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0148 - accuracy: 0.9960 - val_loss: 2.3083 - val_accuracy: 0.6129\n",
            "Epoch 272/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0233 - accuracy: 0.9919 - val_loss: 2.7121 - val_accuracy: 0.6290\n",
            "Epoch 273/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0258 - accuracy: 0.9899 - val_loss: 2.2226 - val_accuracy: 0.6290\n",
            "Epoch 274/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0131 - accuracy: 0.9960 - val_loss: 2.2169 - val_accuracy: 0.6371\n",
            "Epoch 275/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0319 - accuracy: 0.9940 - val_loss: 3.0964 - val_accuracy: 0.6048\n",
            "Epoch 276/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0129 - accuracy: 0.9980 - val_loss: 2.5335 - val_accuracy: 0.6371\n",
            "Epoch 277/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0120 - accuracy: 0.9980 - val_loss: 2.4470 - val_accuracy: 0.6452\n",
            "Epoch 278/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0154 - accuracy: 0.9960 - val_loss: 2.6125 - val_accuracy: 0.6371\n",
            "Epoch 279/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0190 - accuracy: 0.9919 - val_loss: 2.3389 - val_accuracy: 0.6452\n",
            "Epoch 280/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0417 - accuracy: 0.9819 - val_loss: 2.8347 - val_accuracy: 0.5806\n",
            "Epoch 281/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0653 - accuracy: 0.9698 - val_loss: 2.8354 - val_accuracy: 0.5645\n",
            "Epoch 282/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0598 - accuracy: 0.9819 - val_loss: 2.5529 - val_accuracy: 0.6129\n",
            "Epoch 283/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0520 - accuracy: 0.9819 - val_loss: 2.4450 - val_accuracy: 0.6452\n",
            "Epoch 284/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0480 - accuracy: 0.9819 - val_loss: 2.2920 - val_accuracy: 0.5887\n",
            "Epoch 285/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0423 - accuracy: 0.9819 - val_loss: 2.3275 - val_accuracy: 0.6129\n",
            "Epoch 286/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0477 - accuracy: 0.9879 - val_loss: 2.0902 - val_accuracy: 0.5968\n",
            "Epoch 287/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0106 - accuracy: 0.9960 - val_loss: 2.4851 - val_accuracy: 0.5806\n",
            "Epoch 288/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0381 - accuracy: 0.9940 - val_loss: 2.2870 - val_accuracy: 0.6290\n",
            "Epoch 289/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0140 - accuracy: 0.9940 - val_loss: 2.2620 - val_accuracy: 0.6452\n",
            "Epoch 290/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0137 - accuracy: 0.9980 - val_loss: 2.2869 - val_accuracy: 0.6694\n",
            "Epoch 291/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0408 - accuracy: 0.9859 - val_loss: 2.4180 - val_accuracy: 0.6210\n",
            "Epoch 292/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0184 - accuracy: 0.9940 - val_loss: 2.0356 - val_accuracy: 0.6774\n",
            "Epoch 293/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0345 - accuracy: 0.9839 - val_loss: 2.5707 - val_accuracy: 0.6290\n",
            "Epoch 294/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0286 - accuracy: 0.9899 - val_loss: 2.7797 - val_accuracy: 0.5806\n",
            "Epoch 295/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0151 - accuracy: 0.9960 - val_loss: 2.5648 - val_accuracy: 0.6048\n",
            "Epoch 296/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0445 - accuracy: 0.9839 - val_loss: 3.3241 - val_accuracy: 0.5161\n",
            "Epoch 297/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0445 - accuracy: 0.9859 - val_loss: 2.8599 - val_accuracy: 0.5726\n",
            "Epoch 298/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0639 - accuracy: 0.9859 - val_loss: 2.7161 - val_accuracy: 0.5806\n",
            "Epoch 299/1000\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 0.0985 - accuracy: 0.9597 - val_loss: 2.6074 - val_accuracy: 0.6452\n",
            "Epoch 300/1000\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 0.1171 - accuracy: 0.9617 - val_loss: 2.0642 - val_accuracy: 0.6290\n",
            "Epoch 301/1000\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.0834 - accuracy: 0.9698 - val_loss: 1.7981 - val_accuracy: 0.6532\n",
            "Epoch 302/1000\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.0911 - accuracy: 0.9718 - val_loss: 2.1870 - val_accuracy: 0.5726\n",
            "Epoch 303/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0431 - accuracy: 0.9859 - val_loss: 2.0832 - val_accuracy: 0.6129\n",
            "Epoch 304/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0110 - accuracy: 0.9960 - val_loss: 2.2714 - val_accuracy: 0.6532\n",
            "Epoch 305/1000\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 0.0251 - accuracy: 0.9940 - val_loss: 1.9955 - val_accuracy: 0.6371\n",
            "Epoch 306/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0138 - accuracy: 0.9980 - val_loss: 2.1622 - val_accuracy: 0.6452\n",
            "Epoch 307/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0201 - accuracy: 0.9940 - val_loss: 1.9776 - val_accuracy: 0.6532\n",
            "Epoch 308/1000\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 0.0223 - accuracy: 0.9940 - val_loss: 2.5675 - val_accuracy: 0.6210\n",
            "Epoch 309/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0172 - accuracy: 0.9960 - val_loss: 2.0616 - val_accuracy: 0.6694\n",
            "Epoch 310/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 2.0401 - val_accuracy: 0.6694\n",
            "Epoch 311/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 2.2424 - val_accuracy: 0.6452\n",
            "Epoch 312/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.2650 - val_accuracy: 0.6290\n",
            "Epoch 313/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 2.3518 - val_accuracy: 0.6290\n",
            "Epoch 314/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0088 - accuracy: 0.9980 - val_loss: 2.5694 - val_accuracy: 0.6371\n",
            "Epoch 315/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0091 - accuracy: 0.9980 - val_loss: 2.5477 - val_accuracy: 0.6371\n",
            "Epoch 316/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0061 - accuracy: 0.9980 - val_loss: 2.3244 - val_accuracy: 0.6613\n",
            "Epoch 317/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0171 - accuracy: 0.9960 - val_loss: 2.2747 - val_accuracy: 0.6532\n",
            "Epoch 318/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0220 - accuracy: 0.9940 - val_loss: 2.4729 - val_accuracy: 0.6452\n",
            "Epoch 319/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0108 - accuracy: 0.9960 - val_loss: 2.6809 - val_accuracy: 0.6452\n",
            "Epoch 320/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0282 - accuracy: 0.9879 - val_loss: 2.5519 - val_accuracy: 0.6774\n",
            "Epoch 321/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0230 - accuracy: 0.9899 - val_loss: 2.2761 - val_accuracy: 0.6210\n",
            "Epoch 322/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0163 - accuracy: 0.9960 - val_loss: 2.8407 - val_accuracy: 0.6371\n",
            "Epoch 323/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0140 - accuracy: 0.9960 - val_loss: 2.7443 - val_accuracy: 0.6210\n",
            "Epoch 324/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0393 - accuracy: 0.9879 - val_loss: 2.0124 - val_accuracy: 0.6290\n",
            "Epoch 325/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0246 - accuracy: 0.9960 - val_loss: 2.4988 - val_accuracy: 0.5565\n",
            "Epoch 326/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0564 - accuracy: 0.9839 - val_loss: 2.4910 - val_accuracy: 0.5968\n",
            "Epoch 327/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0831 - accuracy: 0.9718 - val_loss: 2.4611 - val_accuracy: 0.5645\n",
            "Epoch 328/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0761 - accuracy: 0.9819 - val_loss: 2.2146 - val_accuracy: 0.5565\n",
            "Epoch 329/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0498 - accuracy: 0.9839 - val_loss: 2.5525 - val_accuracy: 0.5565\n",
            "Epoch 330/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0283 - accuracy: 0.9899 - val_loss: 2.6264 - val_accuracy: 0.5806\n",
            "Epoch 331/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0156 - accuracy: 0.9980 - val_loss: 2.4616 - val_accuracy: 0.6371\n",
            "Epoch 332/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0067 - accuracy: 0.9980 - val_loss: 2.5291 - val_accuracy: 0.6210\n",
            "Epoch 333/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0199 - accuracy: 0.9960 - val_loss: 2.8485 - val_accuracy: 0.5887\n",
            "Epoch 334/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0221 - accuracy: 0.9940 - val_loss: 2.9313 - val_accuracy: 0.5726\n",
            "Epoch 335/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0205 - accuracy: 0.9919 - val_loss: 2.6589 - val_accuracy: 0.6048\n",
            "Epoch 336/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0238 - accuracy: 0.9899 - val_loss: 2.5765 - val_accuracy: 0.6129\n",
            "Epoch 337/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0228 - accuracy: 0.9899 - val_loss: 2.4565 - val_accuracy: 0.6452\n",
            "Epoch 338/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0825 - accuracy: 0.9758 - val_loss: 2.1621 - val_accuracy: 0.6210\n",
            "Epoch 339/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0458 - accuracy: 0.9839 - val_loss: 2.7054 - val_accuracy: 0.5645\n",
            "Epoch 340/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0302 - accuracy: 0.9879 - val_loss: 2.2458 - val_accuracy: 0.6290\n",
            "Epoch 341/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0147 - accuracy: 0.9940 - val_loss: 2.4721 - val_accuracy: 0.6210\n",
            "Epoch 342/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0390 - accuracy: 0.9899 - val_loss: 2.4100 - val_accuracy: 0.6048\n",
            "Epoch 343/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0193 - accuracy: 0.9940 - val_loss: 2.2912 - val_accuracy: 0.6048\n",
            "Epoch 344/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0165 - accuracy: 0.9919 - val_loss: 2.2969 - val_accuracy: 0.6048\n",
            "Epoch 345/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0260 - accuracy: 0.9919 - val_loss: 2.4758 - val_accuracy: 0.6290\n",
            "Epoch 346/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0189 - accuracy: 0.9940 - val_loss: 2.2162 - val_accuracy: 0.6452\n",
            "Epoch 347/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0151 - accuracy: 0.9980 - val_loss: 2.6204 - val_accuracy: 0.6532\n",
            "Epoch 348/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0282 - accuracy: 0.9919 - val_loss: 2.6800 - val_accuracy: 0.6532\n",
            "Epoch 349/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0306 - accuracy: 0.9879 - val_loss: 2.4707 - val_accuracy: 0.6129\n",
            "Epoch 350/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0231 - accuracy: 0.9940 - val_loss: 2.1818 - val_accuracy: 0.5726\n",
            "Epoch 351/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0168 - accuracy: 0.9919 - val_loss: 2.5551 - val_accuracy: 0.5968\n",
            "Epoch 352/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0374 - accuracy: 0.9798 - val_loss: 2.1434 - val_accuracy: 0.5968\n",
            "Epoch 353/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0328 - accuracy: 0.9899 - val_loss: 2.2827 - val_accuracy: 0.6532\n",
            "Epoch 354/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0314 - accuracy: 0.9879 - val_loss: 2.6873 - val_accuracy: 0.5887\n",
            "Epoch 355/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0457 - accuracy: 0.9798 - val_loss: 2.6371 - val_accuracy: 0.6129\n",
            "Epoch 356/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0217 - accuracy: 0.9919 - val_loss: 2.1181 - val_accuracy: 0.6371\n",
            "Epoch 357/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0105 - accuracy: 0.9940 - val_loss: 2.2298 - val_accuracy: 0.6210\n",
            "Epoch 358/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0266 - accuracy: 0.9899 - val_loss: 2.2287 - val_accuracy: 0.6210\n",
            "Epoch 359/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0142 - accuracy: 0.9940 - val_loss: 2.1612 - val_accuracy: 0.6290\n",
            "Epoch 360/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0224 - accuracy: 0.9960 - val_loss: 2.7107 - val_accuracy: 0.5726\n",
            "Epoch 361/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0079 - accuracy: 0.9980 - val_loss: 2.3896 - val_accuracy: 0.6210\n",
            "Epoch 362/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0113 - accuracy: 0.9960 - val_loss: 2.6533 - val_accuracy: 0.5968\n",
            "Epoch 363/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 2.7276 - val_accuracy: 0.5726\n",
            "Epoch 364/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0136 - accuracy: 0.9940 - val_loss: 2.6252 - val_accuracy: 0.5806\n",
            "Epoch 365/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0073 - accuracy: 0.9980 - val_loss: 2.5445 - val_accuracy: 0.6613\n",
            "Epoch 366/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0134 - accuracy: 0.9940 - val_loss: 2.7506 - val_accuracy: 0.6371\n",
            "Epoch 367/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0297 - accuracy: 0.9879 - val_loss: 3.0301 - val_accuracy: 0.5806\n",
            "Epoch 368/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0663 - accuracy: 0.9778 - val_loss: 2.9440 - val_accuracy: 0.5887\n",
            "Epoch 369/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0514 - accuracy: 0.9798 - val_loss: 2.6299 - val_accuracy: 0.5806\n",
            "Epoch 370/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0472 - accuracy: 0.9798 - val_loss: 2.8390 - val_accuracy: 0.5403\n",
            "Epoch 371/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0730 - accuracy: 0.9738 - val_loss: 2.0535 - val_accuracy: 0.6129\n",
            "Epoch 372/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0337 - accuracy: 0.9859 - val_loss: 2.1377 - val_accuracy: 0.5806\n",
            "Epoch 373/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0102 - accuracy: 0.9980 - val_loss: 2.4438 - val_accuracy: 0.6048\n",
            "Epoch 374/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0213 - accuracy: 0.9940 - val_loss: 2.2308 - val_accuracy: 0.5645\n",
            "Epoch 375/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0189 - accuracy: 0.9919 - val_loss: 2.4527 - val_accuracy: 0.5887\n",
            "Epoch 376/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0325 - accuracy: 0.9899 - val_loss: 2.2105 - val_accuracy: 0.6210\n",
            "Epoch 377/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0480 - accuracy: 0.9879 - val_loss: 2.2264 - val_accuracy: 0.6048\n",
            "Epoch 378/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0340 - accuracy: 0.9899 - val_loss: 2.7600 - val_accuracy: 0.5968\n",
            "Epoch 379/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0170 - accuracy: 0.9940 - val_loss: 3.2091 - val_accuracy: 0.5887\n",
            "Epoch 380/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0473 - accuracy: 0.9839 - val_loss: 3.2311 - val_accuracy: 0.5726\n",
            "Epoch 381/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0634 - accuracy: 0.9718 - val_loss: 2.0180 - val_accuracy: 0.6613\n",
            "Epoch 382/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0227 - accuracy: 0.9940 - val_loss: 2.3109 - val_accuracy: 0.6452\n",
            "Epoch 383/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0106 - accuracy: 0.9960 - val_loss: 2.3263 - val_accuracy: 0.6371\n",
            "Epoch 384/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0165 - accuracy: 0.9919 - val_loss: 2.3023 - val_accuracy: 0.6452\n",
            "Epoch 385/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0228 - accuracy: 0.9919 - val_loss: 1.8476 - val_accuracy: 0.6694\n",
            "Epoch 386/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0094 - accuracy: 0.9980 - val_loss: 2.2831 - val_accuracy: 0.6613\n",
            "Epoch 387/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0180 - accuracy: 0.9960 - val_loss: 2.3759 - val_accuracy: 0.6532\n",
            "Epoch 388/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0285 - accuracy: 0.9940 - val_loss: 2.2665 - val_accuracy: 0.6371\n",
            "Epoch 389/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0281 - accuracy: 0.9940 - val_loss: 1.9192 - val_accuracy: 0.5887\n",
            "Epoch 390/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0069 - accuracy: 0.9980 - val_loss: 2.0095 - val_accuracy: 0.6048\n",
            "Epoch 391/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0082 - accuracy: 0.9980 - val_loss: 2.0229 - val_accuracy: 0.6371\n",
            "Epoch 392/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0112 - accuracy: 0.9980 - val_loss: 2.1397 - val_accuracy: 0.6290\n",
            "Epoch 393/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 2.2642 - val_accuracy: 0.6129\n",
            "Epoch 394/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.2766 - val_accuracy: 0.6210\n",
            "Epoch 395/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0100 - accuracy: 0.9960 - val_loss: 2.1508 - val_accuracy: 0.6129\n",
            "Epoch 396/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 2.4152 - val_accuracy: 0.5887\n",
            "Epoch 397/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 2.5250 - val_accuracy: 0.5887\n",
            "Epoch 398/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0062 - accuracy: 0.9980 - val_loss: 2.6406 - val_accuracy: 0.6129\n",
            "Epoch 399/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0596 - accuracy: 0.9859 - val_loss: 2.6928 - val_accuracy: 0.5806\n",
            "Epoch 400/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0628 - accuracy: 0.9758 - val_loss: 3.1686 - val_accuracy: 0.5887\n",
            "Epoch 401/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.1187 - accuracy: 0.9617 - val_loss: 3.7003 - val_accuracy: 0.5968\n",
            "Epoch 402/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.1455 - accuracy: 0.9556 - val_loss: 1.8204 - val_accuracy: 0.5968\n",
            "Epoch 403/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0635 - accuracy: 0.9738 - val_loss: 1.9110 - val_accuracy: 0.6129\n",
            "Epoch 404/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0469 - accuracy: 0.9839 - val_loss: 2.2652 - val_accuracy: 0.6129\n",
            "Epoch 405/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0266 - accuracy: 0.9899 - val_loss: 2.2837 - val_accuracy: 0.6048\n",
            "Epoch 406/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0203 - accuracy: 0.9960 - val_loss: 2.1151 - val_accuracy: 0.5968\n",
            "Epoch 407/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0200 - accuracy: 0.9899 - val_loss: 2.1747 - val_accuracy: 0.6532\n",
            "Epoch 408/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0145 - accuracy: 0.9940 - val_loss: 2.0791 - val_accuracy: 0.6452\n",
            "Epoch 409/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0090 - accuracy: 0.9980 - val_loss: 1.9943 - val_accuracy: 0.6371\n",
            "Epoch 410/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0049 - accuracy: 0.9980 - val_loss: 2.1413 - val_accuracy: 0.6452\n",
            "Epoch 411/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 2.2290 - val_accuracy: 0.6129\n",
            "Epoch 412/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.2764 - val_accuracy: 0.6210\n",
            "Epoch 413/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.3779 - val_accuracy: 0.6290\n",
            "Epoch 414/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 2.2468 - val_accuracy: 0.6210\n",
            "Epoch 415/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 2.4471 - val_accuracy: 0.6129\n",
            "Epoch 416/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.4613 - val_accuracy: 0.6129\n",
            "Epoch 417/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0125 - accuracy: 0.9960 - val_loss: 2.7603 - val_accuracy: 0.5887\n",
            "Epoch 418/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0240 - accuracy: 0.9940 - val_loss: 2.7518 - val_accuracy: 0.6129\n",
            "Epoch 419/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0351 - accuracy: 0.9859 - val_loss: 3.0601 - val_accuracy: 0.5726\n",
            "Epoch 420/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0428 - accuracy: 0.9839 - val_loss: 1.9948 - val_accuracy: 0.6532\n",
            "Epoch 421/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0445 - accuracy: 0.9899 - val_loss: 2.8080 - val_accuracy: 0.6210\n",
            "Epoch 422/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0484 - accuracy: 0.9839 - val_loss: 2.5501 - val_accuracy: 0.6048\n",
            "Epoch 423/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0274 - accuracy: 0.9919 - val_loss: 3.1547 - val_accuracy: 0.6048\n",
            "Epoch 424/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0655 - accuracy: 0.9819 - val_loss: 3.3191 - val_accuracy: 0.6048\n",
            "Epoch 425/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0638 - accuracy: 0.9819 - val_loss: 2.5354 - val_accuracy: 0.6129\n",
            "Epoch 426/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0221 - accuracy: 0.9919 - val_loss: 2.4273 - val_accuracy: 0.5484\n",
            "Epoch 427/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0233 - accuracy: 0.9919 - val_loss: 2.9467 - val_accuracy: 0.5403\n",
            "Epoch 428/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0401 - accuracy: 0.9879 - val_loss: 2.4906 - val_accuracy: 0.5484\n",
            "Epoch 429/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0327 - accuracy: 0.9899 - val_loss: 2.8818 - val_accuracy: 0.5565\n",
            "Epoch 430/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0201 - accuracy: 0.9960 - val_loss: 2.8847 - val_accuracy: 0.5726\n",
            "Epoch 431/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0155 - accuracy: 0.9940 - val_loss: 2.5313 - val_accuracy: 0.5968\n",
            "Epoch 432/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0139 - accuracy: 0.9960 - val_loss: 2.4244 - val_accuracy: 0.5645\n",
            "Epoch 433/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0078 - accuracy: 0.9980 - val_loss: 2.3158 - val_accuracy: 0.6452\n",
            "Epoch 434/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 2.3709 - val_accuracy: 0.6371\n",
            "Epoch 435/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.4963 - val_accuracy: 0.6210\n",
            "Epoch 436/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.4626 - val_accuracy: 0.6210\n",
            "Epoch 437/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0046 - accuracy: 0.9980 - val_loss: 2.7153 - val_accuracy: 0.6371\n",
            "Epoch 438/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0121 - accuracy: 0.9960 - val_loss: 2.5587 - val_accuracy: 0.6048\n",
            "Epoch 439/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0083 - accuracy: 0.9980 - val_loss: 2.5369 - val_accuracy: 0.6048\n",
            "Epoch 440/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 2.2318 - val_accuracy: 0.6452\n",
            "Epoch 441/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0121 - accuracy: 0.9980 - val_loss: 2.2599 - val_accuracy: 0.6855\n",
            "Epoch 442/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0231 - accuracy: 0.9940 - val_loss: 3.0496 - val_accuracy: 0.6371\n",
            "Epoch 443/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0440 - accuracy: 0.9819 - val_loss: 2.6862 - val_accuracy: 0.6290\n",
            "Epoch 444/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0736 - accuracy: 0.9819 - val_loss: 2.1291 - val_accuracy: 0.6855\n",
            "Epoch 445/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0391 - accuracy: 0.9879 - val_loss: 2.4630 - val_accuracy: 0.6452\n",
            "Epoch 446/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0513 - accuracy: 0.9798 - val_loss: 2.3480 - val_accuracy: 0.5806\n",
            "Epoch 447/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0233 - accuracy: 0.9879 - val_loss: 2.5263 - val_accuracy: 0.5968\n",
            "Epoch 448/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0625 - accuracy: 0.9738 - val_loss: 2.3914 - val_accuracy: 0.6048\n",
            "Epoch 449/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0306 - accuracy: 0.9899 - val_loss: 2.4400 - val_accuracy: 0.5887\n",
            "Epoch 450/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0239 - accuracy: 0.9919 - val_loss: 2.1746 - val_accuracy: 0.6452\n",
            "Epoch 451/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0129 - accuracy: 0.9960 - val_loss: 2.4651 - val_accuracy: 0.6452\n",
            "Epoch 452/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0145 - accuracy: 0.9960 - val_loss: 2.6151 - val_accuracy: 0.6532\n",
            "Epoch 453/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0158 - accuracy: 0.9960 - val_loss: 2.9314 - val_accuracy: 0.6290\n",
            "Epoch 454/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0238 - accuracy: 0.9899 - val_loss: 2.7729 - val_accuracy: 0.6210\n",
            "Epoch 455/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0173 - accuracy: 0.9960 - val_loss: 2.7183 - val_accuracy: 0.5887\n",
            "Epoch 456/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0176 - accuracy: 0.9919 - val_loss: 2.8269 - val_accuracy: 0.6452\n",
            "Epoch 457/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0158 - accuracy: 0.9960 - val_loss: 3.1272 - val_accuracy: 0.5726\n",
            "Epoch 458/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0100 - accuracy: 0.9960 - val_loss: 2.8720 - val_accuracy: 0.6371\n",
            "Epoch 459/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 2.8096 - val_accuracy: 0.6452\n",
            "Epoch 460/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 2.6931 - val_accuracy: 0.6452\n",
            "Epoch 461/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.8054 - val_accuracy: 0.6613\n",
            "Epoch 462/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 3.0943 - val_accuracy: 0.6532\n",
            "Epoch 463/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 2.9448 - val_accuracy: 0.6532\n",
            "Epoch 464/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.8271 - val_accuracy: 0.6613\n",
            "Epoch 465/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 2.9967 - val_accuracy: 0.6210\n",
            "Epoch 466/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0044 - accuracy: 0.9980 - val_loss: 2.7851 - val_accuracy: 0.6290\n",
            "Epoch 467/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0540 - accuracy: 0.9879 - val_loss: 2.9305 - val_accuracy: 0.5403\n",
            "Epoch 468/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0090 - accuracy: 0.9960 - val_loss: 2.8997 - val_accuracy: 0.5403\n",
            "Epoch 469/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 2.6611 - val_accuracy: 0.5968\n",
            "Epoch 470/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.7014 - val_accuracy: 0.6210\n",
            "Epoch 471/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.7527 - val_accuracy: 0.6371\n",
            "Epoch 472/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.8462 - val_accuracy: 0.6290\n",
            "Epoch 473/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 2.8865 - val_accuracy: 0.6210\n",
            "Epoch 474/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.6255 - val_accuracy: 0.6371\n",
            "Epoch 475/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.9621 - val_accuracy: 0.6048\n",
            "Epoch 476/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0035 - accuracy: 0.9980 - val_loss: 3.1194 - val_accuracy: 0.6129\n",
            "Epoch 477/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0037 - accuracy: 0.9980 - val_loss: 3.4071 - val_accuracy: 0.5968\n",
            "Epoch 478/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0509 - accuracy: 0.9839 - val_loss: 4.8756 - val_accuracy: 0.5726\n",
            "Epoch 479/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.1057 - accuracy: 0.9778 - val_loss: 2.3694 - val_accuracy: 0.5726\n",
            "Epoch 480/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0797 - accuracy: 0.9798 - val_loss: 2.5632 - val_accuracy: 0.5806\n",
            "Epoch 481/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0536 - accuracy: 0.9879 - val_loss: 2.7101 - val_accuracy: 0.5806\n",
            "Epoch 482/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0541 - accuracy: 0.9879 - val_loss: 2.4971 - val_accuracy: 0.6210\n",
            "Epoch 483/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0664 - accuracy: 0.9798 - val_loss: 1.9679 - val_accuracy: 0.6048\n",
            "Epoch 484/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0242 - accuracy: 0.9960 - val_loss: 2.1040 - val_accuracy: 0.6532\n",
            "Epoch 485/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0124 - accuracy: 0.9960 - val_loss: 1.8699 - val_accuracy: 0.6694\n",
            "Epoch 486/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0152 - accuracy: 0.9960 - val_loss: 1.8528 - val_accuracy: 0.6290\n",
            "Epoch 487/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 2.0190 - val_accuracy: 0.6532\n",
            "Epoch 488/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 2.0194 - val_accuracy: 0.6371\n",
            "Epoch 489/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0047 - accuracy: 0.9980 - val_loss: 2.0524 - val_accuracy: 0.6290\n",
            "Epoch 490/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 2.2133 - val_accuracy: 0.6371\n",
            "Epoch 491/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 2.3779 - val_accuracy: 0.5726\n",
            "Epoch 492/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0072 - accuracy: 0.9960 - val_loss: 2.3700 - val_accuracy: 0.5968\n",
            "Epoch 493/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0041 - accuracy: 0.9980 - val_loss: 2.1502 - val_accuracy: 0.6935\n",
            "Epoch 494/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.2162 - val_accuracy: 0.6613\n",
            "Epoch 495/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.3053 - val_accuracy: 0.6452\n",
            "Epoch 496/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0066 - accuracy: 0.9980 - val_loss: 2.3249 - val_accuracy: 0.6048\n",
            "Epoch 497/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0236 - accuracy: 0.9899 - val_loss: 2.6377 - val_accuracy: 0.5968\n",
            "Epoch 498/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0555 - accuracy: 0.9859 - val_loss: 2.0503 - val_accuracy: 0.7016\n",
            "Epoch 499/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0552 - accuracy: 0.9758 - val_loss: 3.5009 - val_accuracy: 0.5726\n",
            "Epoch 500/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0762 - accuracy: 0.9718 - val_loss: 2.2628 - val_accuracy: 0.6210\n",
            "Epoch 501/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0529 - accuracy: 0.9758 - val_loss: 2.9633 - val_accuracy: 0.5806\n",
            "Epoch 502/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0345 - accuracy: 0.9839 - val_loss: 2.4427 - val_accuracy: 0.5887\n",
            "Epoch 503/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0574 - accuracy: 0.9859 - val_loss: 2.3364 - val_accuracy: 0.5968\n",
            "Epoch 504/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0352 - accuracy: 0.9859 - val_loss: 2.0613 - val_accuracy: 0.5887\n",
            "Epoch 505/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0335 - accuracy: 0.9879 - val_loss: 2.6702 - val_accuracy: 0.5645\n",
            "Epoch 506/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0325 - accuracy: 0.9879 - val_loss: 2.6090 - val_accuracy: 0.6210\n",
            "Epoch 507/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0119 - accuracy: 0.9980 - val_loss: 2.3942 - val_accuracy: 0.6371\n",
            "Epoch 508/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0119 - accuracy: 0.9980 - val_loss: 2.4418 - val_accuracy: 0.5968\n",
            "Epoch 509/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 2.4849 - val_accuracy: 0.6129\n",
            "Epoch 510/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0059 - accuracy: 0.9980 - val_loss: 2.9102 - val_accuracy: 0.5968\n",
            "Epoch 511/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.9038 - val_accuracy: 0.5968\n",
            "Epoch 512/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.8398 - val_accuracy: 0.5968\n",
            "Epoch 513/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0140 - accuracy: 0.9960 - val_loss: 3.0024 - val_accuracy: 0.6210\n",
            "Epoch 514/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0110 - accuracy: 0.9960 - val_loss: 2.7355 - val_accuracy: 0.5968\n",
            "Epoch 515/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0225 - accuracy: 0.9960 - val_loss: 2.4555 - val_accuracy: 0.6210\n",
            "Epoch 516/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0371 - accuracy: 0.9940 - val_loss: 3.0120 - val_accuracy: 0.5887\n",
            "Epoch 517/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0339 - accuracy: 0.9879 - val_loss: 3.4216 - val_accuracy: 0.6129\n",
            "Epoch 518/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0208 - accuracy: 0.9960 - val_loss: 2.5961 - val_accuracy: 0.6452\n",
            "Epoch 519/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0212 - accuracy: 0.9899 - val_loss: 2.7659 - val_accuracy: 0.6129\n",
            "Epoch 520/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0248 - accuracy: 0.9940 - val_loss: 3.3396 - val_accuracy: 0.5645\n",
            "Epoch 521/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0197 - accuracy: 0.9899 - val_loss: 2.8862 - val_accuracy: 0.6129\n",
            "Epoch 522/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0186 - accuracy: 0.9940 - val_loss: 2.7742 - val_accuracy: 0.5645\n",
            "Epoch 523/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0152 - accuracy: 0.9940 - val_loss: 2.6948 - val_accuracy: 0.6129\n",
            "Epoch 524/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 2.4001 - val_accuracy: 0.6452\n",
            "Epoch 525/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.4745 - val_accuracy: 0.6210\n",
            "Epoch 526/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0067 - accuracy: 0.9980 - val_loss: 2.7656 - val_accuracy: 0.6290\n",
            "Epoch 527/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.7232 - val_accuracy: 0.6129\n",
            "Epoch 528/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.7083 - val_accuracy: 0.6290\n",
            "Epoch 529/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.7580 - val_accuracy: 0.6048\n",
            "Epoch 530/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0174 - accuracy: 0.9960 - val_loss: 2.8370 - val_accuracy: 0.6290\n",
            "Epoch 531/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0307 - accuracy: 0.9899 - val_loss: 2.8675 - val_accuracy: 0.6210\n",
            "Epoch 532/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0189 - accuracy: 0.9940 - val_loss: 2.6306 - val_accuracy: 0.6452\n",
            "Epoch 533/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0209 - accuracy: 0.9899 - val_loss: 2.4423 - val_accuracy: 0.6371\n",
            "Epoch 534/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0241 - accuracy: 0.9899 - val_loss: 2.7319 - val_accuracy: 0.6532\n",
            "Epoch 535/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0197 - accuracy: 0.9919 - val_loss: 3.0705 - val_accuracy: 0.5565\n",
            "Epoch 536/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0394 - accuracy: 0.9899 - val_loss: 2.5478 - val_accuracy: 0.6210\n",
            "Epoch 537/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0447 - accuracy: 0.9859 - val_loss: 2.5172 - val_accuracy: 0.6290\n",
            "Epoch 538/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0572 - accuracy: 0.9819 - val_loss: 2.7558 - val_accuracy: 0.5968\n",
            "Epoch 539/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0268 - accuracy: 0.9879 - val_loss: 1.9303 - val_accuracy: 0.6935\n",
            "Epoch 540/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0322 - accuracy: 0.9879 - val_loss: 2.1179 - val_accuracy: 0.6452\n",
            "Epoch 541/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0290 - accuracy: 0.9919 - val_loss: 1.7255 - val_accuracy: 0.6371\n",
            "Epoch 542/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 2.0246 - val_accuracy: 0.6210\n",
            "Epoch 543/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.1608 - val_accuracy: 0.6371\n",
            "Epoch 544/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0056 - accuracy: 0.9980 - val_loss: 2.1577 - val_accuracy: 0.6290\n",
            "Epoch 545/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 2.0968 - val_accuracy: 0.6452\n",
            "Epoch 546/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.1607 - val_accuracy: 0.6210\n",
            "Epoch 547/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 9.0656e-04 - accuracy: 1.0000 - val_loss: 2.2168 - val_accuracy: 0.6210\n",
            "Epoch 548/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0248 - accuracy: 0.9879 - val_loss: 2.3443 - val_accuracy: 0.6613\n",
            "Epoch 549/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 2.5173 - val_accuracy: 0.6452\n",
            "Epoch 550/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0139 - accuracy: 0.9940 - val_loss: 2.5655 - val_accuracy: 0.6290\n",
            "Epoch 551/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0210 - accuracy: 0.9919 - val_loss: 2.4584 - val_accuracy: 0.6613\n",
            "Epoch 552/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0508 - accuracy: 0.9859 - val_loss: 2.8924 - val_accuracy: 0.6371\n",
            "Epoch 553/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0188 - accuracy: 0.9919 - val_loss: 2.4702 - val_accuracy: 0.6290\n",
            "Epoch 554/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0477 - accuracy: 0.9839 - val_loss: 2.8602 - val_accuracy: 0.6290\n",
            "Epoch 555/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0420 - accuracy: 0.9879 - val_loss: 2.4409 - val_accuracy: 0.5806\n",
            "Epoch 556/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0299 - accuracy: 0.9879 - val_loss: 2.8616 - val_accuracy: 0.5887\n",
            "Epoch 557/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0141 - accuracy: 0.9940 - val_loss: 3.0107 - val_accuracy: 0.6129\n",
            "Epoch 558/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0039 - accuracy: 0.9980 - val_loss: 3.0449 - val_accuracy: 0.6210\n",
            "Epoch 559/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 2.8446 - val_accuracy: 0.6290\n",
            "Epoch 560/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 2.6830 - val_accuracy: 0.6210\n",
            "Epoch 561/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0049 - accuracy: 0.9980 - val_loss: 2.5138 - val_accuracy: 0.6129\n",
            "Epoch 562/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0314 - accuracy: 0.9899 - val_loss: 2.7499 - val_accuracy: 0.6210\n",
            "Epoch 563/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0253 - accuracy: 0.9899 - val_loss: 2.8534 - val_accuracy: 0.6129\n",
            "Epoch 564/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0279 - accuracy: 0.9919 - val_loss: 2.4817 - val_accuracy: 0.6452\n",
            "Epoch 565/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 2.8258 - val_accuracy: 0.6452\n",
            "Epoch 566/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0207 - accuracy: 0.9940 - val_loss: 3.2123 - val_accuracy: 0.6129\n",
            "Epoch 567/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0305 - accuracy: 0.9859 - val_loss: 3.0120 - val_accuracy: 0.6048\n",
            "Epoch 568/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0194 - accuracy: 0.9940 - val_loss: 2.4604 - val_accuracy: 0.6613\n",
            "Epoch 569/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0625 - accuracy: 0.9839 - val_loss: 2.7954 - val_accuracy: 0.5887\n",
            "Epoch 570/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0536 - accuracy: 0.9839 - val_loss: 3.1411 - val_accuracy: 0.6210\n",
            "Epoch 571/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0123 - accuracy: 0.9940 - val_loss: 2.7233 - val_accuracy: 0.5726\n",
            "Epoch 572/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0198 - accuracy: 0.9919 - val_loss: 2.6925 - val_accuracy: 0.5968\n",
            "Epoch 573/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0122 - accuracy: 0.9980 - val_loss: 2.6829 - val_accuracy: 0.5806\n",
            "Epoch 574/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0106 - accuracy: 0.9960 - val_loss: 2.5006 - val_accuracy: 0.5968\n",
            "Epoch 575/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.6599 - val_accuracy: 0.5726\n",
            "Epoch 576/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0145 - accuracy: 0.9960 - val_loss: 2.8907 - val_accuracy: 0.5645\n",
            "Epoch 577/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0100 - accuracy: 0.9980 - val_loss: 2.9221 - val_accuracy: 0.5806\n",
            "Epoch 578/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.9096 - val_accuracy: 0.5726\n",
            "Epoch 579/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 3.0469 - val_accuracy: 0.5806\n",
            "Epoch 580/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0145 - accuracy: 0.9960 - val_loss: 2.8031 - val_accuracy: 0.5806\n",
            "Epoch 581/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0266 - accuracy: 0.9899 - val_loss: 3.2233 - val_accuracy: 0.5968\n",
            "Epoch 582/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0190 - accuracy: 0.9940 - val_loss: 3.4555 - val_accuracy: 0.5565\n",
            "Epoch 583/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0227 - accuracy: 0.9899 - val_loss: 2.8104 - val_accuracy: 0.6371\n",
            "Epoch 584/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0160 - accuracy: 0.9940 - val_loss: 2.7240 - val_accuracy: 0.6371\n",
            "Epoch 585/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 2.8124 - val_accuracy: 0.6129\n",
            "Epoch 586/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 2.9729 - val_accuracy: 0.6129\n",
            "Epoch 587/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0040 - accuracy: 0.9980 - val_loss: 3.0119 - val_accuracy: 0.6290\n",
            "Epoch 588/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0088 - accuracy: 0.9960 - val_loss: 3.3293 - val_accuracy: 0.5968\n",
            "Epoch 589/1000\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 0.0335 - accuracy: 0.9899 - val_loss: 3.1095 - val_accuracy: 0.5968\n",
            "Epoch 590/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0225 - accuracy: 0.9940 - val_loss: 2.9483 - val_accuracy: 0.6048\n",
            "Epoch 591/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0280 - accuracy: 0.9879 - val_loss: 2.4975 - val_accuracy: 0.6210\n",
            "Epoch 592/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0234 - accuracy: 0.9940 - val_loss: 2.4295 - val_accuracy: 0.6129\n",
            "Epoch 593/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0219 - accuracy: 0.9940 - val_loss: 2.7956 - val_accuracy: 0.5968\n",
            "Epoch 594/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0820 - accuracy: 0.9758 - val_loss: 2.9828 - val_accuracy: 0.6371\n",
            "Epoch 595/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.1180 - accuracy: 0.9637 - val_loss: 2.9079 - val_accuracy: 0.5645\n",
            "Epoch 596/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0412 - accuracy: 0.9798 - val_loss: 2.4927 - val_accuracy: 0.5645\n",
            "Epoch 597/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0148 - accuracy: 0.9940 - val_loss: 2.5951 - val_accuracy: 0.5887\n",
            "Epoch 598/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 2.5643 - val_accuracy: 0.6210\n",
            "Epoch 599/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 2.5110 - val_accuracy: 0.5968\n",
            "Epoch 600/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0090 - accuracy: 0.9980 - val_loss: 2.5409 - val_accuracy: 0.5968\n",
            "Epoch 601/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.5582 - val_accuracy: 0.6048\n",
            "Epoch 602/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.5806 - val_accuracy: 0.6048\n",
            "Epoch 603/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.6033 - val_accuracy: 0.6290\n",
            "Epoch 604/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.7005 - val_accuracy: 0.6371\n",
            "Epoch 605/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.6732 - val_accuracy: 0.6371\n",
            "Epoch 606/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 4.4046e-04 - accuracy: 1.0000 - val_loss: 2.6375 - val_accuracy: 0.6371\n",
            "Epoch 607/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0027 - accuracy: 0.9980 - val_loss: 2.8090 - val_accuracy: 0.6290\n",
            "Epoch 608/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.8123 - val_accuracy: 0.6371\n",
            "Epoch 609/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.7721 - val_accuracy: 0.6048\n",
            "Epoch 610/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0081 - accuracy: 0.9960 - val_loss: 2.5688 - val_accuracy: 0.6210\n",
            "Epoch 611/1000\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 0.0195 - accuracy: 0.9960 - val_loss: 2.9654 - val_accuracy: 0.5968\n",
            "Epoch 612/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0351 - accuracy: 0.9940 - val_loss: 3.2812 - val_accuracy: 0.5968\n",
            "Epoch 613/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0216 - accuracy: 0.9919 - val_loss: 2.2843 - val_accuracy: 0.6129\n",
            "Epoch 614/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0451 - accuracy: 0.9859 - val_loss: 2.4030 - val_accuracy: 0.5887\n",
            "Epoch 615/1000\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 0.0299 - accuracy: 0.9879 - val_loss: 2.6308 - val_accuracy: 0.5887\n",
            "Epoch 616/1000\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 2.6861 - val_accuracy: 0.5887\n",
            "Epoch 617/1000\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 0.0104 - accuracy: 0.9960 - val_loss: 3.2968 - val_accuracy: 0.5645\n",
            "Epoch 618/1000\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 3.0142 - val_accuracy: 0.5565\n",
            "Epoch 619/1000\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.0168 - accuracy: 0.9919 - val_loss: 2.6628 - val_accuracy: 0.6371\n",
            "Epoch 620/1000\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 2.7480 - val_accuracy: 0.6371\n",
            "Epoch 621/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0048 - accuracy: 0.9980 - val_loss: 3.0213 - val_accuracy: 0.5806\n",
            "Epoch 622/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 3.0411 - val_accuracy: 0.5887\n",
            "Epoch 623/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 3.1232 - val_accuracy: 0.5968\n",
            "Epoch 624/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 3.4812 - val_accuracy: 0.6371\n",
            "Epoch 625/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 3.5292 - val_accuracy: 0.6129\n",
            "Epoch 626/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 3.4649 - val_accuracy: 0.6048\n",
            "Epoch 627/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0076 - accuracy: 0.9960 - val_loss: 3.1385 - val_accuracy: 0.6048\n",
            "Epoch 628/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0156 - accuracy: 0.9940 - val_loss: 3.9220 - val_accuracy: 0.5645\n",
            "Epoch 629/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 3.6391 - val_accuracy: 0.5806\n",
            "Epoch 630/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 3.6642 - val_accuracy: 0.5645\n",
            "Epoch 631/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 3.5451 - val_accuracy: 0.5565\n",
            "Epoch 632/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 3.5794 - val_accuracy: 0.5726\n",
            "Epoch 633/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0070 - accuracy: 0.9960 - val_loss: 4.1190 - val_accuracy: 0.5484\n",
            "Epoch 634/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 3.9913 - val_accuracy: 0.5968\n",
            "Epoch 635/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0092 - accuracy: 0.9980 - val_loss: 3.7480 - val_accuracy: 0.6290\n",
            "Epoch 636/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0339 - accuracy: 0.9839 - val_loss: 3.7269 - val_accuracy: 0.5887\n",
            "Epoch 637/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0976 - accuracy: 0.9738 - val_loss: 5.6030 - val_accuracy: 0.5806\n",
            "Epoch 638/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.1558 - accuracy: 0.9536 - val_loss: 2.2525 - val_accuracy: 0.6452\n",
            "Epoch 639/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0639 - accuracy: 0.9718 - val_loss: 1.5192 - val_accuracy: 0.6613\n",
            "Epoch 640/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0342 - accuracy: 0.9899 - val_loss: 1.4191 - val_accuracy: 0.6694\n",
            "Epoch 641/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0232 - accuracy: 0.9899 - val_loss: 1.9182 - val_accuracy: 0.6371\n",
            "Epoch 642/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0223 - accuracy: 0.9919 - val_loss: 1.9872 - val_accuracy: 0.6371\n",
            "Epoch 643/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0245 - accuracy: 0.9940 - val_loss: 2.1340 - val_accuracy: 0.6371\n",
            "Epoch 644/1000\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 0.0354 - accuracy: 0.9819 - val_loss: 2.4470 - val_accuracy: 0.5806\n",
            "Epoch 645/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0094 - accuracy: 0.9980 - val_loss: 2.3894 - val_accuracy: 0.5968\n",
            "Epoch 646/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0119 - accuracy: 0.9960 - val_loss: 2.1523 - val_accuracy: 0.6210\n",
            "Epoch 647/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0125 - accuracy: 0.9960 - val_loss: 2.1891 - val_accuracy: 0.5887\n",
            "Epoch 648/1000\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 2.7628 - val_accuracy: 0.6290\n",
            "Epoch 649/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 2.6915 - val_accuracy: 0.6210\n",
            "Epoch 650/1000\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.6543 - val_accuracy: 0.5968\n",
            "Epoch 651/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0059 - accuracy: 0.9980 - val_loss: 2.6929 - val_accuracy: 0.6210\n",
            "Epoch 652/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0048 - accuracy: 0.9980 - val_loss: 2.8120 - val_accuracy: 0.6129\n",
            "Epoch 653/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.6796 - val_accuracy: 0.6210\n",
            "Epoch 654/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.5939 - val_accuracy: 0.6210\n",
            "Epoch 655/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.8200 - val_accuracy: 0.6371\n",
            "Epoch 656/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 7.8720e-04 - accuracy: 1.0000 - val_loss: 2.8103 - val_accuracy: 0.6290\n",
            "Epoch 657/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.9220 - val_accuracy: 0.6048\n",
            "Epoch 658/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.8833 - val_accuracy: 0.6129\n",
            "Epoch 659/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.8211 - val_accuracy: 0.6452\n",
            "Epoch 660/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 5.8287e-04 - accuracy: 1.0000 - val_loss: 2.8152 - val_accuracy: 0.6290\n",
            "Epoch 661/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.7358 - val_accuracy: 0.6774\n",
            "Epoch 662/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 5.0107e-04 - accuracy: 1.0000 - val_loss: 2.7148 - val_accuracy: 0.6694\n",
            "Epoch 663/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 2.7684 - val_accuracy: 0.6613\n",
            "Epoch 664/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0076 - accuracy: 0.9980 - val_loss: 2.8392 - val_accuracy: 0.6694\n",
            "Epoch 665/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 3.3781 - val_accuracy: 0.6290\n",
            "Epoch 666/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 5.0308e-04 - accuracy: 1.0000 - val_loss: 3.3359 - val_accuracy: 0.6210\n",
            "Epoch 667/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0086 - accuracy: 0.9980 - val_loss: 2.9984 - val_accuracy: 0.6048\n",
            "Epoch 668/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0042 - accuracy: 0.9980 - val_loss: 2.9511 - val_accuracy: 0.6290\n",
            "Epoch 669/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0340 - accuracy: 0.9899 - val_loss: 3.2182 - val_accuracy: 0.6210\n",
            "Epoch 670/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.1042 - accuracy: 0.9698 - val_loss: 1.9208 - val_accuracy: 0.6613\n",
            "Epoch 671/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0460 - accuracy: 0.9899 - val_loss: 2.6324 - val_accuracy: 0.5887\n",
            "Epoch 672/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0290 - accuracy: 0.9859 - val_loss: 2.3849 - val_accuracy: 0.6210\n",
            "Epoch 673/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0153 - accuracy: 0.9940 - val_loss: 2.1545 - val_accuracy: 0.6290\n",
            "Epoch 674/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0227 - accuracy: 0.9919 - val_loss: 2.5297 - val_accuracy: 0.6129\n",
            "Epoch 675/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0175 - accuracy: 0.9899 - val_loss: 2.8163 - val_accuracy: 0.5726\n",
            "Epoch 676/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0075 - accuracy: 0.9980 - val_loss: 2.8488 - val_accuracy: 0.5968\n",
            "Epoch 677/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 2.6128 - val_accuracy: 0.6129\n",
            "Epoch 678/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.6671 - val_accuracy: 0.6129\n",
            "Epoch 679/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0070 - accuracy: 0.9960 - val_loss: 2.5995 - val_accuracy: 0.5806\n",
            "Epoch 680/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 2.5848 - val_accuracy: 0.5645\n",
            "Epoch 681/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 2.6147 - val_accuracy: 0.5887\n",
            "Epoch 682/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.6569 - val_accuracy: 0.5887\n",
            "Epoch 683/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0078 - accuracy: 0.9960 - val_loss: 3.0922 - val_accuracy: 0.6290\n",
            "Epoch 684/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0080 - accuracy: 0.9960 - val_loss: 3.2680 - val_accuracy: 0.5968\n",
            "Epoch 685/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0116 - accuracy: 0.9960 - val_loss: 3.0886 - val_accuracy: 0.5968\n",
            "Epoch 686/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0209 - accuracy: 0.9940 - val_loss: 3.3746 - val_accuracy: 0.5968\n",
            "Epoch 687/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.1267 - accuracy: 0.9778 - val_loss: 4.0911 - val_accuracy: 0.5081\n",
            "Epoch 688/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.1063 - accuracy: 0.9677 - val_loss: 2.8684 - val_accuracy: 0.5323\n",
            "Epoch 689/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0206 - accuracy: 0.9980 - val_loss: 2.8281 - val_accuracy: 0.5968\n",
            "Epoch 690/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0400 - accuracy: 0.9859 - val_loss: 3.1331 - val_accuracy: 0.5806\n",
            "Epoch 691/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0243 - accuracy: 0.9919 - val_loss: 3.3776 - val_accuracy: 0.5484\n",
            "Epoch 692/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0232 - accuracy: 0.9940 - val_loss: 2.4192 - val_accuracy: 0.5968\n",
            "Epoch 693/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0129 - accuracy: 0.9960 - val_loss: 2.3256 - val_accuracy: 0.6290\n",
            "Epoch 694/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0092 - accuracy: 0.9940 - val_loss: 2.4930 - val_accuracy: 0.6210\n",
            "Epoch 695/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0119 - accuracy: 0.9960 - val_loss: 2.4357 - val_accuracy: 0.6290\n",
            "Epoch 696/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.4641 - val_accuracy: 0.6452\n",
            "Epoch 697/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0041 - accuracy: 0.9980 - val_loss: 2.4377 - val_accuracy: 0.6371\n",
            "Epoch 698/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0095 - accuracy: 0.9940 - val_loss: 2.6627 - val_accuracy: 0.6290\n",
            "Epoch 699/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0047 - accuracy: 0.9960 - val_loss: 2.6721 - val_accuracy: 0.6129\n",
            "Epoch 700/1000\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.6102 - val_accuracy: 0.5968\n",
            "Epoch 701/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0030 - accuracy: 0.9980 - val_loss: 2.6573 - val_accuracy: 0.6048\n",
            "Epoch 702/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 2.6823 - val_accuracy: 0.6048\n",
            "Epoch 703/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0031 - accuracy: 0.9980 - val_loss: 3.0408 - val_accuracy: 0.5968\n",
            "Epoch 704/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0068 - accuracy: 0.9980 - val_loss: 2.5064 - val_accuracy: 0.6210\n",
            "Epoch 705/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 2.4902 - val_accuracy: 0.6048\n",
            "Epoch 706/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 2.6227 - val_accuracy: 0.6290\n",
            "Epoch 707/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 6.5133e-04 - accuracy: 1.0000 - val_loss: 2.6760 - val_accuracy: 0.6290\n",
            "Epoch 708/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0079 - accuracy: 0.9940 - val_loss: 2.6321 - val_accuracy: 0.6210\n",
            "Epoch 709/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0030 - accuracy: 0.9980 - val_loss: 3.1079 - val_accuracy: 0.6048\n",
            "Epoch 710/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 3.0270 - val_accuracy: 0.6129\n",
            "Epoch 711/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.8869 - val_accuracy: 0.6290\n",
            "Epoch 712/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.6151 - val_accuracy: 0.6290\n",
            "Epoch 713/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0054 - accuracy: 0.9980 - val_loss: 2.6157 - val_accuracy: 0.6129\n",
            "Epoch 714/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0098 - accuracy: 0.9919 - val_loss: 2.6467 - val_accuracy: 0.6452\n",
            "Epoch 715/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.1269 - accuracy: 0.9859 - val_loss: 2.7123 - val_accuracy: 0.6452\n",
            "Epoch 716/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0396 - accuracy: 0.9879 - val_loss: 2.6786 - val_accuracy: 0.5484\n",
            "Epoch 717/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0301 - accuracy: 0.9839 - val_loss: 2.5830 - val_accuracy: 0.6048\n",
            "Epoch 718/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0191 - accuracy: 0.9919 - val_loss: 3.0909 - val_accuracy: 0.6290\n",
            "Epoch 719/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0301 - accuracy: 0.9899 - val_loss: 2.5014 - val_accuracy: 0.6210\n",
            "Epoch 720/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0132 - accuracy: 0.9960 - val_loss: 2.5340 - val_accuracy: 0.6048\n",
            "Epoch 721/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0142 - accuracy: 0.9960 - val_loss: 2.4016 - val_accuracy: 0.6371\n",
            "Epoch 722/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0134 - accuracy: 0.9960 - val_loss: 2.3698 - val_accuracy: 0.6210\n",
            "Epoch 723/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0821 - accuracy: 0.9819 - val_loss: 2.1977 - val_accuracy: 0.6290\n",
            "Epoch 724/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0348 - accuracy: 0.9899 - val_loss: 2.3832 - val_accuracy: 0.5968\n",
            "Epoch 725/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0140 - accuracy: 0.9940 - val_loss: 2.5993 - val_accuracy: 0.5806\n",
            "Epoch 726/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 2.3070 - val_accuracy: 0.5968\n",
            "Epoch 727/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0106 - accuracy: 0.9960 - val_loss: 2.1237 - val_accuracy: 0.5726\n",
            "Epoch 728/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0121 - accuracy: 0.9960 - val_loss: 2.7145 - val_accuracy: 0.5645\n",
            "Epoch 729/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0090 - accuracy: 0.9960 - val_loss: 2.9899 - val_accuracy: 0.5565\n",
            "Epoch 730/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0128 - accuracy: 0.9960 - val_loss: 2.9016 - val_accuracy: 0.5806\n",
            "Epoch 731/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0283 - accuracy: 0.9879 - val_loss: 2.7552 - val_accuracy: 0.6048\n",
            "Epoch 732/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0163 - accuracy: 0.9899 - val_loss: 2.6322 - val_accuracy: 0.6210\n",
            "Epoch 733/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 2.6453 - val_accuracy: 0.5968\n",
            "Epoch 734/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0111 - accuracy: 0.9919 - val_loss: 2.5290 - val_accuracy: 0.5806\n",
            "Epoch 735/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0084 - accuracy: 0.9960 - val_loss: 2.4362 - val_accuracy: 0.6129\n",
            "Epoch 736/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 2.3999 - val_accuracy: 0.6210\n",
            "Epoch 737/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 2.3954 - val_accuracy: 0.6290\n",
            "Epoch 738/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.4362 - val_accuracy: 0.6129\n",
            "Epoch 739/1000\n",
            "31/31 [==============================] - 0s 15ms/step - loss: 0.0024 - accuracy: 0.9980 - val_loss: 2.5036 - val_accuracy: 0.6371\n",
            "Epoch 740/1000\n",
            "31/31 [==============================] - 1s 17ms/step - loss: 0.0024 - accuracy: 0.9980 - val_loss: 2.4691 - val_accuracy: 0.6452\n",
            "Epoch 741/1000\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.4901 - val_accuracy: 0.6452\n",
            "Epoch 742/1000\n",
            "31/31 [==============================] - 1s 16ms/step - loss: 0.0071 - accuracy: 0.9980 - val_loss: 2.5016 - val_accuracy: 0.6048\n",
            "Epoch 743/1000\n",
            "31/31 [==============================] - 1s 17ms/step - loss: 0.0019 - accuracy: 0.9980 - val_loss: 2.3951 - val_accuracy: 0.6290\n",
            "Epoch 744/1000\n",
            "31/31 [==============================] - 1s 19ms/step - loss: 7.5894e-04 - accuracy: 1.0000 - val_loss: 2.3708 - val_accuracy: 0.6452\n",
            "Epoch 745/1000\n",
            "31/31 [==============================] - 1s 16ms/step - loss: 0.0073 - accuracy: 0.9960 - val_loss: 2.6054 - val_accuracy: 0.6290\n",
            "Epoch 746/1000\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 0.0124 - accuracy: 0.9940 - val_loss: 2.3841 - val_accuracy: 0.6452\n",
            "Epoch 747/1000\n",
            "31/31 [==============================] - 1s 19ms/step - loss: 0.0108 - accuracy: 0.9960 - val_loss: 2.4965 - val_accuracy: 0.5968\n",
            "Epoch 748/1000\n",
            "31/31 [==============================] - 1s 17ms/step - loss: 0.0172 - accuracy: 0.9960 - val_loss: 2.3673 - val_accuracy: 0.6210\n",
            "Epoch 749/1000\n",
            "31/31 [==============================] - 1s 16ms/step - loss: 0.0225 - accuracy: 0.9919 - val_loss: 2.3762 - val_accuracy: 0.6210\n",
            "Epoch 750/1000\n",
            "31/31 [==============================] - 1s 20ms/step - loss: 0.0280 - accuracy: 0.9919 - val_loss: 2.6958 - val_accuracy: 0.5968\n",
            "Epoch 751/1000\n",
            "31/31 [==============================] - 1s 20ms/step - loss: 0.0237 - accuracy: 0.9960 - val_loss: 2.7130 - val_accuracy: 0.6129\n",
            "Epoch 752/1000\n",
            "31/31 [==============================] - 1s 20ms/step - loss: 0.0076 - accuracy: 0.9980 - val_loss: 3.2133 - val_accuracy: 0.5887\n",
            "Epoch 753/1000\n",
            "31/31 [==============================] - 1s 18ms/step - loss: 0.0084 - accuracy: 0.9980 - val_loss: 2.5857 - val_accuracy: 0.6532\n",
            "Epoch 754/1000\n",
            "31/31 [==============================] - 1s 16ms/step - loss: 0.0133 - accuracy: 0.9960 - val_loss: 2.9597 - val_accuracy: 0.6290\n",
            "Epoch 755/1000\n",
            "31/31 [==============================] - 1s 18ms/step - loss: 0.0524 - accuracy: 0.9899 - val_loss: 3.1958 - val_accuracy: 0.6210\n",
            "Epoch 756/1000\n",
            "31/31 [==============================] - 1s 17ms/step - loss: 0.0505 - accuracy: 0.9859 - val_loss: 3.6481 - val_accuracy: 0.6129\n",
            "Epoch 757/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0266 - accuracy: 0.9879 - val_loss: 3.5433 - val_accuracy: 0.6129\n",
            "Epoch 758/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0646 - accuracy: 0.9778 - val_loss: 2.7693 - val_accuracy: 0.6452\n",
            "Epoch 759/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0237 - accuracy: 0.9919 - val_loss: 2.5895 - val_accuracy: 0.6371\n",
            "Epoch 760/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0102 - accuracy: 0.9940 - val_loss: 2.4822 - val_accuracy: 0.6452\n",
            "Epoch 761/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0434 - accuracy: 0.9960 - val_loss: 2.5071 - val_accuracy: 0.6371\n",
            "Epoch 762/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0280 - accuracy: 0.9879 - val_loss: 2.2299 - val_accuracy: 0.6694\n",
            "Epoch 763/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0328 - accuracy: 0.9919 - val_loss: 2.0915 - val_accuracy: 0.6210\n",
            "Epoch 764/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0163 - accuracy: 0.9940 - val_loss: 2.3082 - val_accuracy: 0.5968\n",
            "Epoch 765/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0166 - accuracy: 0.9940 - val_loss: 2.0836 - val_accuracy: 0.6371\n",
            "Epoch 766/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 2.0517 - val_accuracy: 0.6532\n",
            "Epoch 767/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.0820 - val_accuracy: 0.6694\n",
            "Epoch 768/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0064 - accuracy: 0.9980 - val_loss: 2.1557 - val_accuracy: 0.6613\n",
            "Epoch 769/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0181 - accuracy: 0.9940 - val_loss: 2.1637 - val_accuracy: 0.6694\n",
            "Epoch 770/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0125 - accuracy: 0.9960 - val_loss: 2.2026 - val_accuracy: 0.6210\n",
            "Epoch 771/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0086 - accuracy: 0.9980 - val_loss: 2.8995 - val_accuracy: 0.5887\n",
            "Epoch 772/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0093 - accuracy: 0.9960 - val_loss: 2.3395 - val_accuracy: 0.6371\n",
            "Epoch 773/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0049 - accuracy: 0.9980 - val_loss: 2.0939 - val_accuracy: 0.6452\n",
            "Epoch 774/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0031 - accuracy: 0.9980 - val_loss: 2.1162 - val_accuracy: 0.6613\n",
            "Epoch 775/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0077 - accuracy: 0.9960 - val_loss: 2.1392 - val_accuracy: 0.6774\n",
            "Epoch 776/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0233 - accuracy: 0.9940 - val_loss: 2.1573 - val_accuracy: 0.6855\n",
            "Epoch 777/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0131 - accuracy: 0.9960 - val_loss: 2.3341 - val_accuracy: 0.6532\n",
            "Epoch 778/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0045 - accuracy: 0.9980 - val_loss: 2.7241 - val_accuracy: 0.6290\n",
            "Epoch 779/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 2.6485 - val_accuracy: 0.6129\n",
            "Epoch 780/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.7640 - val_accuracy: 0.6048\n",
            "Epoch 781/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.8057 - val_accuracy: 0.6210\n",
            "Epoch 782/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0045 - accuracy: 0.9980 - val_loss: 2.6786 - val_accuracy: 0.6290\n",
            "Epoch 783/1000\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 0.0157 - accuracy: 0.9940 - val_loss: 2.8566 - val_accuracy: 0.6129\n",
            "Epoch 784/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0197 - accuracy: 0.9980 - val_loss: 2.7327 - val_accuracy: 0.5887\n",
            "Epoch 785/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0210 - accuracy: 0.9940 - val_loss: 2.9979 - val_accuracy: 0.6452\n",
            "Epoch 786/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0565 - accuracy: 0.9819 - val_loss: 3.5262 - val_accuracy: 0.5968\n",
            "Epoch 787/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0286 - accuracy: 0.9879 - val_loss: 3.0259 - val_accuracy: 0.6048\n",
            "Epoch 788/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0065 - accuracy: 0.9960 - val_loss: 2.7763 - val_accuracy: 0.6371\n",
            "Epoch 789/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0148 - accuracy: 0.9960 - val_loss: 2.3415 - val_accuracy: 0.6290\n",
            "Epoch 790/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.6572 - val_accuracy: 0.6290\n",
            "Epoch 791/1000\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 0.0055 - accuracy: 0.9960 - val_loss: 2.7375 - val_accuracy: 0.6452\n",
            "Epoch 792/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0092 - accuracy: 0.9960 - val_loss: 2.8282 - val_accuracy: 0.6452\n",
            "Epoch 793/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 2.8353 - val_accuracy: 0.6452\n",
            "Epoch 794/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0113 - accuracy: 0.9940 - val_loss: 2.7414 - val_accuracy: 0.6532\n",
            "Epoch 795/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0087 - accuracy: 0.9960 - val_loss: 2.6502 - val_accuracy: 0.6532\n",
            "Epoch 796/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0322 - accuracy: 0.9839 - val_loss: 2.5347 - val_accuracy: 0.6452\n",
            "Epoch 797/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.8715 - val_accuracy: 0.6371\n",
            "Epoch 798/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0160 - accuracy: 0.9960 - val_loss: 3.2464 - val_accuracy: 0.6290\n",
            "Epoch 799/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0238 - accuracy: 0.9919 - val_loss: 3.1264 - val_accuracy: 0.6048\n",
            "Epoch 800/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0118 - accuracy: 0.9940 - val_loss: 3.0181 - val_accuracy: 0.6129\n",
            "Epoch 801/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0300 - accuracy: 0.9940 - val_loss: 2.5509 - val_accuracy: 0.5726\n",
            "Epoch 802/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0099 - accuracy: 0.9960 - val_loss: 2.6560 - val_accuracy: 0.6129\n",
            "Epoch 803/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0236 - accuracy: 0.9940 - val_loss: 2.2299 - val_accuracy: 0.6290\n",
            "Epoch 804/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0118 - accuracy: 0.9980 - val_loss: 2.4853 - val_accuracy: 0.6694\n",
            "Epoch 805/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0062 - accuracy: 0.9960 - val_loss: 3.0948 - val_accuracy: 0.6290\n",
            "Epoch 806/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0103 - accuracy: 0.9980 - val_loss: 2.7245 - val_accuracy: 0.6210\n",
            "Epoch 807/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0148 - accuracy: 0.9919 - val_loss: 2.7278 - val_accuracy: 0.6129\n",
            "Epoch 808/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0219 - accuracy: 0.9940 - val_loss: 2.6154 - val_accuracy: 0.6210\n",
            "Epoch 809/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 2.7308 - val_accuracy: 0.5887\n",
            "Epoch 810/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0107 - accuracy: 0.9980 - val_loss: 2.6813 - val_accuracy: 0.6129\n",
            "Epoch 811/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0110 - accuracy: 0.9940 - val_loss: 3.1521 - val_accuracy: 0.5806\n",
            "Epoch 812/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0065 - accuracy: 0.9980 - val_loss: 3.0835 - val_accuracy: 0.5968\n",
            "Epoch 813/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0385 - accuracy: 0.9859 - val_loss: 2.9764 - val_accuracy: 0.5968\n",
            "Epoch 814/1000\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 0.0195 - accuracy: 0.9919 - val_loss: 2.6185 - val_accuracy: 0.6048\n",
            "Epoch 815/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0155 - accuracy: 0.9940 - val_loss: 3.3684 - val_accuracy: 0.6048\n",
            "Epoch 816/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0314 - accuracy: 0.9899 - val_loss: 2.3811 - val_accuracy: 0.6290\n",
            "Epoch 817/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 2.4130 - val_accuracy: 0.6129\n",
            "Epoch 818/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0071 - accuracy: 0.9960 - val_loss: 2.2531 - val_accuracy: 0.6210\n",
            "Epoch 819/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0081 - accuracy: 0.9980 - val_loss: 2.5738 - val_accuracy: 0.5806\n",
            "Epoch 820/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0136 - accuracy: 0.9940 - val_loss: 2.9321 - val_accuracy: 0.5565\n",
            "Epoch 821/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0093 - accuracy: 0.9940 - val_loss: 2.8676 - val_accuracy: 0.5806\n",
            "Epoch 822/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0086 - accuracy: 0.9980 - val_loss: 2.6535 - val_accuracy: 0.5968\n",
            "Epoch 823/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0112 - accuracy: 0.9960 - val_loss: 2.7964 - val_accuracy: 0.5726\n",
            "Epoch 824/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0293 - accuracy: 0.9940 - val_loss: 2.7512 - val_accuracy: 0.6210\n",
            "Epoch 825/1000\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 0.0176 - accuracy: 0.9919 - val_loss: 2.7356 - val_accuracy: 0.6613\n",
            "Epoch 826/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 3.1733 - val_accuracy: 0.6371\n",
            "Epoch 827/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 3.3223 - val_accuracy: 0.5887\n",
            "Epoch 828/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0096 - accuracy: 0.9960 - val_loss: 3.3034 - val_accuracy: 0.5484\n",
            "Epoch 829/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0045 - accuracy: 0.9980 - val_loss: 2.8042 - val_accuracy: 0.6129\n",
            "Epoch 830/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0092 - accuracy: 0.9980 - val_loss: 2.5096 - val_accuracy: 0.6290\n",
            "Epoch 831/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0094 - accuracy: 0.9960 - val_loss: 2.8728 - val_accuracy: 0.6129\n",
            "Epoch 832/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0071 - accuracy: 0.9980 - val_loss: 2.5126 - val_accuracy: 0.6290\n",
            "Epoch 833/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.6711 - val_accuracy: 0.6452\n",
            "Epoch 834/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.7809 - val_accuracy: 0.6532\n",
            "Epoch 835/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 3.4932e-04 - accuracy: 1.0000 - val_loss: 2.8158 - val_accuracy: 0.6613\n",
            "Epoch 836/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.8423 - val_accuracy: 0.6532\n",
            "Epoch 837/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 4.8148e-04 - accuracy: 1.0000 - val_loss: 2.8598 - val_accuracy: 0.6694\n",
            "Epoch 838/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 9.8645e-04 - accuracy: 1.0000 - val_loss: 2.9337 - val_accuracy: 0.6452\n",
            "Epoch 839/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.9980 - val_loss: 3.0679 - val_accuracy: 0.6210\n",
            "Epoch 840/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 3.0121 - val_accuracy: 0.6210\n",
            "Epoch 841/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 7.8977e-04 - accuracy: 1.0000 - val_loss: 2.9126 - val_accuracy: 0.6613\n",
            "Epoch 842/1000\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 3.8032e-04 - accuracy: 1.0000 - val_loss: 2.9312 - val_accuracy: 0.6694\n",
            "Epoch 843/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 5.4758e-04 - accuracy: 1.0000 - val_loss: 2.9694 - val_accuracy: 0.6613\n",
            "Epoch 844/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 8.5100e-04 - accuracy: 1.0000 - val_loss: 2.9865 - val_accuracy: 0.6452\n",
            "Epoch 845/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 1.5117e-04 - accuracy: 1.0000 - val_loss: 3.0110 - val_accuracy: 0.6452\n",
            "Epoch 846/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 5.0533e-04 - accuracy: 1.0000 - val_loss: 3.0168 - val_accuracy: 0.6452\n",
            "Epoch 847/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0036 - accuracy: 0.9980 - val_loss: 3.3152 - val_accuracy: 0.6048\n",
            "Epoch 848/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 5.3416e-04 - accuracy: 1.0000 - val_loss: 3.2495 - val_accuracy: 0.6210\n",
            "Epoch 849/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 3.0547e-04 - accuracy: 1.0000 - val_loss: 3.2214 - val_accuracy: 0.6290\n",
            "Epoch 850/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 3.8559e-04 - accuracy: 1.0000 - val_loss: 3.2101 - val_accuracy: 0.6371\n",
            "Epoch 851/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 5.7557e-04 - accuracy: 1.0000 - val_loss: 3.2539 - val_accuracy: 0.6371\n",
            "Epoch 852/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 2.5492e-04 - accuracy: 1.0000 - val_loss: 3.2635 - val_accuracy: 0.6371\n",
            "Epoch 853/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0125 - accuracy: 0.9960 - val_loss: 2.7930 - val_accuracy: 0.6452\n",
            "Epoch 854/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0052 - accuracy: 0.9980 - val_loss: 3.2623 - val_accuracy: 0.6290\n",
            "Epoch 855/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0034 - accuracy: 0.9980 - val_loss: 3.3514 - val_accuracy: 0.6452\n",
            "Epoch 856/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0316 - accuracy: 0.9919 - val_loss: 3.1730 - val_accuracy: 0.6452\n",
            "Epoch 857/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0907 - accuracy: 0.9879 - val_loss: 2.6146 - val_accuracy: 0.6210\n",
            "Epoch 858/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0185 - accuracy: 0.9940 - val_loss: 3.0595 - val_accuracy: 0.6048\n",
            "Epoch 859/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0329 - accuracy: 0.9919 - val_loss: 3.3903 - val_accuracy: 0.6290\n",
            "Epoch 860/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0120 - accuracy: 0.9960 - val_loss: 3.4684 - val_accuracy: 0.6129\n",
            "Epoch 861/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0300 - accuracy: 0.9879 - val_loss: 4.0166 - val_accuracy: 0.5806\n",
            "Epoch 862/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0177 - accuracy: 0.9940 - val_loss: 3.3842 - val_accuracy: 0.5323\n",
            "Epoch 863/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0271 - accuracy: 0.9919 - val_loss: 3.4293 - val_accuracy: 0.5887\n",
            "Epoch 864/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 3.3560 - val_accuracy: 0.5968\n",
            "Epoch 865/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0145 - accuracy: 0.9940 - val_loss: 3.4809 - val_accuracy: 0.5887\n",
            "Epoch 866/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0565 - accuracy: 0.9879 - val_loss: 3.4831 - val_accuracy: 0.5887\n",
            "Epoch 867/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.1590 - accuracy: 0.9738 - val_loss: 2.7145 - val_accuracy: 0.6048\n",
            "Epoch 868/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.1147 - accuracy: 0.9778 - val_loss: 2.7771 - val_accuracy: 0.5645\n",
            "Epoch 869/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0280 - accuracy: 0.9919 - val_loss: 2.2167 - val_accuracy: 0.6210\n",
            "Epoch 870/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 2.2449 - val_accuracy: 0.6290\n",
            "Epoch 871/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 2.3482 - val_accuracy: 0.6210\n",
            "Epoch 872/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0056 - accuracy: 0.9980 - val_loss: 2.4620 - val_accuracy: 0.6290\n",
            "Epoch 873/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 2.4666 - val_accuracy: 0.6048\n",
            "Epoch 874/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 2.4737 - val_accuracy: 0.6371\n",
            "Epoch 875/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0045 - accuracy: 0.9980 - val_loss: 2.5231 - val_accuracy: 0.6613\n",
            "Epoch 876/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0055 - accuracy: 0.9980 - val_loss: 2.5518 - val_accuracy: 0.6290\n",
            "Epoch 877/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0049 - accuracy: 0.9980 - val_loss: 2.6452 - val_accuracy: 0.6129\n",
            "Epoch 878/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0141 - accuracy: 0.9940 - val_loss: 2.3540 - val_accuracy: 0.6129\n",
            "Epoch 879/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0034 - accuracy: 0.9980 - val_loss: 2.4341 - val_accuracy: 0.6290\n",
            "Epoch 880/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.5152 - val_accuracy: 0.6290\n",
            "Epoch 881/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0113 - accuracy: 0.9960 - val_loss: 2.5403 - val_accuracy: 0.6048\n",
            "Epoch 882/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0075 - accuracy: 0.9980 - val_loss: 2.9011 - val_accuracy: 0.5887\n",
            "Epoch 883/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.9379 - val_accuracy: 0.6048\n",
            "Epoch 884/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0085 - accuracy: 0.9980 - val_loss: 2.8845 - val_accuracy: 0.5887\n",
            "Epoch 885/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0047 - accuracy: 0.9980 - val_loss: 2.9096 - val_accuracy: 0.5726\n",
            "Epoch 886/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 2.8598 - val_accuracy: 0.6048\n",
            "Epoch 887/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0335 - accuracy: 0.9960 - val_loss: 2.6398 - val_accuracy: 0.6371\n",
            "Epoch 888/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0116 - accuracy: 0.9960 - val_loss: 3.1510 - val_accuracy: 0.5887\n",
            "Epoch 889/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0315 - accuracy: 0.9940 - val_loss: 2.9326 - val_accuracy: 0.5726\n",
            "Epoch 890/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0205 - accuracy: 0.9899 - val_loss: 2.9178 - val_accuracy: 0.5806\n",
            "Epoch 891/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0054 - accuracy: 0.9980 - val_loss: 3.0871 - val_accuracy: 0.5968\n",
            "Epoch 892/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0066 - accuracy: 0.9960 - val_loss: 2.9514 - val_accuracy: 0.5968\n",
            "Epoch 893/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 2.8555 - val_accuracy: 0.5968\n",
            "Epoch 894/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.9506 - val_accuracy: 0.5726\n",
            "Epoch 895/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0184 - accuracy: 0.9919 - val_loss: 3.2600 - val_accuracy: 0.6452\n",
            "Epoch 896/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0038 - accuracy: 0.9980 - val_loss: 3.2083 - val_accuracy: 0.6048\n",
            "Epoch 897/1000\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 0.0111 - accuracy: 0.9960 - val_loss: 2.5772 - val_accuracy: 0.6613\n",
            "Epoch 898/1000\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.0046 - accuracy: 0.9980 - val_loss: 2.5079 - val_accuracy: 0.5806\n",
            "Epoch 899/1000\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.0043 - accuracy: 0.9980 - val_loss: 2.4895 - val_accuracy: 0.6048\n",
            "Epoch 900/1000\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.0066 - accuracy: 0.9980 - val_loss: 2.3652 - val_accuracy: 0.6371\n",
            "Epoch 901/1000\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 0.0063 - accuracy: 0.9980 - val_loss: 2.4952 - val_accuracy: 0.6290\n",
            "Epoch 902/1000\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 0.0068 - accuracy: 0.9960 - val_loss: 2.9661 - val_accuracy: 0.5887\n",
            "Epoch 903/1000\n",
            "31/31 [==============================] - 0s 14ms/step - loss: 0.0158 - accuracy: 0.9919 - val_loss: 3.0811 - val_accuracy: 0.5968\n",
            "Epoch 904/1000\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 0.0070 - accuracy: 0.9960 - val_loss: 3.6087 - val_accuracy: 0.5403\n",
            "Epoch 905/1000\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 3.3224 - val_accuracy: 0.5645\n",
            "Epoch 906/1000\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.0342 - accuracy: 0.9919 - val_loss: 3.3307 - val_accuracy: 0.5565\n",
            "Epoch 907/1000\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.0150 - accuracy: 0.9919 - val_loss: 3.4428 - val_accuracy: 0.5645\n",
            "Epoch 908/1000\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 0.0128 - accuracy: 0.9960 - val_loss: 3.2766 - val_accuracy: 0.6129\n",
            "Epoch 909/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0045 - accuracy: 0.9980 - val_loss: 2.8884 - val_accuracy: 0.5968\n",
            "Epoch 910/1000\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 0.0019 - accuracy: 0.9980 - val_loss: 2.7051 - val_accuracy: 0.5806\n",
            "Epoch 911/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 2.7310 - val_accuracy: 0.5726\n",
            "Epoch 912/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0126 - accuracy: 0.9980 - val_loss: 3.5823 - val_accuracy: 0.5645\n",
            "Epoch 913/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0059 - accuracy: 0.9960 - val_loss: 3.3859 - val_accuracy: 0.5968\n",
            "Epoch 914/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0222 - accuracy: 0.9899 - val_loss: 2.9363 - val_accuracy: 0.6532\n",
            "Epoch 915/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.1026 - accuracy: 0.9879 - val_loss: 3.2323 - val_accuracy: 0.6210\n",
            "Epoch 916/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0283 - accuracy: 0.9879 - val_loss: 2.8339 - val_accuracy: 0.6210\n",
            "Epoch 917/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0173 - accuracy: 0.9940 - val_loss: 2.5940 - val_accuracy: 0.6129\n",
            "Epoch 918/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0055 - accuracy: 0.9980 - val_loss: 2.5333 - val_accuracy: 0.5968\n",
            "Epoch 919/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0128 - accuracy: 0.9940 - val_loss: 3.2291 - val_accuracy: 0.5968\n",
            "Epoch 920/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0117 - accuracy: 0.9940 - val_loss: 3.0185 - val_accuracy: 0.5726\n",
            "Epoch 921/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0192 - accuracy: 0.9940 - val_loss: 2.4684 - val_accuracy: 0.6290\n",
            "Epoch 922/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.4689 - val_accuracy: 0.6210\n",
            "Epoch 923/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 2.5871 - val_accuracy: 0.6048\n",
            "Epoch 924/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.5918 - val_accuracy: 0.6048\n",
            "Epoch 925/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 5.6374e-04 - accuracy: 1.0000 - val_loss: 2.6021 - val_accuracy: 0.6129\n",
            "Epoch 926/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 4.9221e-04 - accuracy: 1.0000 - val_loss: 2.6102 - val_accuracy: 0.6210\n",
            "Epoch 927/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.6102 - val_accuracy: 0.6290\n",
            "Epoch 928/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.6907 - val_accuracy: 0.6371\n",
            "Epoch 929/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 4.4252e-04 - accuracy: 1.0000 - val_loss: 2.7339 - val_accuracy: 0.6210\n",
            "Epoch 930/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 5.3886e-04 - accuracy: 1.0000 - val_loss: 2.7704 - val_accuracy: 0.6210\n",
            "Epoch 931/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0064 - accuracy: 0.9960 - val_loss: 3.0088 - val_accuracy: 0.6290\n",
            "Epoch 932/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0143 - accuracy: 0.9940 - val_loss: 2.9864 - val_accuracy: 0.5968\n",
            "Epoch 933/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0269 - accuracy: 0.9839 - val_loss: 2.9505 - val_accuracy: 0.6452\n",
            "Epoch 934/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0375 - accuracy: 0.9919 - val_loss: 3.1522 - val_accuracy: 0.6129\n",
            "Epoch 935/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0049 - accuracy: 0.9980 - val_loss: 3.0220 - val_accuracy: 0.6048\n",
            "Epoch 936/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0077 - accuracy: 0.9960 - val_loss: 2.9118 - val_accuracy: 0.6048\n",
            "Epoch 937/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 2.9930 - val_accuracy: 0.6129\n",
            "Epoch 938/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 2.5979 - val_accuracy: 0.6613\n",
            "Epoch 939/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0035 - accuracy: 0.9980 - val_loss: 2.5627 - val_accuracy: 0.6371\n",
            "Epoch 940/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0119 - accuracy: 0.9960 - val_loss: 2.9522 - val_accuracy: 0.6048\n",
            "Epoch 941/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0068 - accuracy: 0.9980 - val_loss: 4.0701 - val_accuracy: 0.5726\n",
            "Epoch 942/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 3.5585 - val_accuracy: 0.5726\n",
            "Epoch 943/1000\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 6.1104e-04 - accuracy: 1.0000 - val_loss: 3.4933 - val_accuracy: 0.5806\n",
            "Epoch 944/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 6.3921e-04 - accuracy: 1.0000 - val_loss: 3.4348 - val_accuracy: 0.5806\n",
            "Epoch 945/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 3.3763 - val_accuracy: 0.5726\n",
            "Epoch 946/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 6.2108e-04 - accuracy: 1.0000 - val_loss: 3.3644 - val_accuracy: 0.5806\n",
            "Epoch 947/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 6.6498e-04 - accuracy: 1.0000 - val_loss: 3.3230 - val_accuracy: 0.5968\n",
            "Epoch 948/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0102 - accuracy: 0.9960 - val_loss: 3.1865 - val_accuracy: 0.5887\n",
            "Epoch 949/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 3.2711 - val_accuracy: 0.5645\n",
            "Epoch 950/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0067 - accuracy: 0.9980 - val_loss: 3.2151 - val_accuracy: 0.6210\n",
            "Epoch 951/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0171 - accuracy: 0.9940 - val_loss: 3.4881 - val_accuracy: 0.5887\n",
            "Epoch 952/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0302 - accuracy: 0.9919 - val_loss: 3.2383 - val_accuracy: 0.6694\n",
            "Epoch 953/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0471 - accuracy: 0.9859 - val_loss: 3.6305 - val_accuracy: 0.5887\n",
            "Epoch 954/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0360 - accuracy: 0.9859 - val_loss: 2.9486 - val_accuracy: 0.5726\n",
            "Epoch 955/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0249 - accuracy: 0.9919 - val_loss: 3.2542 - val_accuracy: 0.6129\n",
            "Epoch 956/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0207 - accuracy: 0.9919 - val_loss: 2.6360 - val_accuracy: 0.6129\n",
            "Epoch 957/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0167 - accuracy: 0.9919 - val_loss: 3.1412 - val_accuracy: 0.6048\n",
            "Epoch 958/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 2.9207 - val_accuracy: 0.6210\n",
            "Epoch 959/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.8994 - val_accuracy: 0.6371\n",
            "Epoch 960/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.8613 - val_accuracy: 0.6452\n",
            "Epoch 961/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 4.7924e-04 - accuracy: 1.0000 - val_loss: 2.8331 - val_accuracy: 0.6532\n",
            "Epoch 962/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 2.7350 - val_accuracy: 0.6452\n",
            "Epoch 963/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0064 - accuracy: 0.9980 - val_loss: 2.7908 - val_accuracy: 0.6210\n",
            "Epoch 964/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0076 - accuracy: 0.9980 - val_loss: 3.0358 - val_accuracy: 0.6694\n",
            "Epoch 965/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0120 - accuracy: 0.9940 - val_loss: 2.7871 - val_accuracy: 0.6532\n",
            "Epoch 966/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 2.7674 - val_accuracy: 0.6210\n",
            "Epoch 967/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.7756 - val_accuracy: 0.6210\n",
            "Epoch 968/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.8144 - val_accuracy: 0.6290\n",
            "Epoch 969/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 4.3084e-04 - accuracy: 1.0000 - val_loss: 2.8641 - val_accuracy: 0.6452\n",
            "Epoch 970/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 8.0490e-04 - accuracy: 1.0000 - val_loss: 2.8326 - val_accuracy: 0.6452\n",
            "Epoch 971/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0035 - accuracy: 0.9980 - val_loss: 2.6795 - val_accuracy: 0.6371\n",
            "Epoch 972/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 3.0488 - val_accuracy: 0.6613\n",
            "Epoch 973/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 5.9487e-04 - accuracy: 1.0000 - val_loss: 3.2185 - val_accuracy: 0.6613\n",
            "Epoch 974/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0036 - accuracy: 0.9980 - val_loss: 3.7506 - val_accuracy: 0.5968\n",
            "Epoch 975/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 3.6636 - val_accuracy: 0.5968\n",
            "Epoch 976/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 3.2016e-04 - accuracy: 1.0000 - val_loss: 3.4516 - val_accuracy: 0.6210\n",
            "Epoch 977/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 9.1328e-04 - accuracy: 1.0000 - val_loss: 3.4734 - val_accuracy: 0.6048\n",
            "Epoch 978/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 6.5267e-04 - accuracy: 1.0000 - val_loss: 3.5411 - val_accuracy: 0.6210\n",
            "Epoch 979/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 3.3797 - val_accuracy: 0.6210\n",
            "Epoch 980/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 1.4326e-04 - accuracy: 1.0000 - val_loss: 3.3293 - val_accuracy: 0.6210\n",
            "Epoch 981/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0027 - accuracy: 0.9980 - val_loss: 3.2595 - val_accuracy: 0.6371\n",
            "Epoch 982/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0040 - accuracy: 0.9980 - val_loss: 3.0949 - val_accuracy: 0.6855\n",
            "Epoch 983/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0246 - accuracy: 0.9940 - val_loss: 3.5429 - val_accuracy: 0.6210\n",
            "Epoch 984/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0716 - accuracy: 0.9778 - val_loss: 3.4388 - val_accuracy: 0.5645\n",
            "Epoch 985/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0730 - accuracy: 0.9798 - val_loss: 3.4925 - val_accuracy: 0.5726\n",
            "Epoch 986/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0312 - accuracy: 0.9940 - val_loss: 2.6241 - val_accuracy: 0.6129\n",
            "Epoch 987/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0277 - accuracy: 0.9919 - val_loss: 2.2379 - val_accuracy: 0.6048\n",
            "Epoch 988/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0505 - accuracy: 0.9879 - val_loss: 2.9542 - val_accuracy: 0.5645\n",
            "Epoch 989/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0363 - accuracy: 0.9859 - val_loss: 2.1190 - val_accuracy: 0.6129\n",
            "Epoch 990/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0268 - accuracy: 0.9919 - val_loss: 2.3277 - val_accuracy: 0.5887\n",
            "Epoch 991/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0164 - accuracy: 0.9899 - val_loss: 2.6597 - val_accuracy: 0.5968\n",
            "Epoch 992/1000\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 2.6274 - val_accuracy: 0.5887\n",
            "Epoch 993/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0070 - accuracy: 0.9960 - val_loss: 2.5340 - val_accuracy: 0.5645\n",
            "Epoch 994/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0131 - accuracy: 0.9960 - val_loss: 2.4169 - val_accuracy: 0.6532\n",
            "Epoch 995/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0259 - accuracy: 0.9940 - val_loss: 2.5670 - val_accuracy: 0.5968\n",
            "Epoch 996/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0053 - accuracy: 0.9980 - val_loss: 2.6969 - val_accuracy: 0.6129\n",
            "Epoch 997/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0097 - accuracy: 0.9980 - val_loss: 2.6145 - val_accuracy: 0.5887\n",
            "Epoch 998/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0208 - accuracy: 0.9940 - val_loss: 2.6759 - val_accuracy: 0.5887\n",
            "Epoch 999/1000\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0094 - accuracy: 0.9960 - val_loss: 3.9766 - val_accuracy: 0.5242\n",
            "Epoch 1000/1000\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0077 - accuracy: 0.9980 - val_loss: 2.3112 - val_accuracy: 0.6048\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history[\"accuracy\"])\n",
        "plt.plot(history.history[\"val_accuracy\"])\n",
        "plt.title(\"Model accuracy\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.legend([\"Train\", \"Test\"])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mz2r72SUPfTI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "90733590-ef89-4815-b5c7-7855d8524637"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(x_test)"
      ],
      "metadata": {
        "id": "rzfKm3VW8RQc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred.shape[0]"
      ],
      "metadata": {
        "id": "-Ksxq9IfdxqI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred[2][0]"
      ],
      "metadata": {
        "id": "MprXutMydyMH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_accuracy(y_pred, y_test):\n",
        "  total_correct = 0.0\n",
        "  for i in range(y_pred.shape[0]):\n",
        "    if (np.round(y_pred[i]) == y_test[i]):\n",
        "      total_correct += 1.0\n",
        "  return total_correct / y_pred.shape[0]"
      ],
      "metadata": {
        "id": "S2YdRKlgd0kC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_accuracy(y_pred, y_test)"
      ],
      "metadata": {
        "id": "AEsoq68vd2Vp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}